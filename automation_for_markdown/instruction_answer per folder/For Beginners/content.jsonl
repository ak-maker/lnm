[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Basic MIMO Simulations<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#Basic-MIMO-Simulations\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this notebook, you will learn how to setup simulations of MIMO transmissions over a flat-fading channel.\n    \nHere is a schematic diagram of the system model with all required components:\n    \n    \nYou will learn how to:\n \n- Use the FastFadingChannel class\n- Apply spatial antenna correlation\n- Implement LMMSE detection with perfect channel knowledge\n- Run BER/SER simulations\n\n    \nWe will first walk through the configuration of all components of the system model, before building a general Keras model which will allow you to run efficiently simulations with different parameter settings.\n\n# Table of Content\n## GPU Configuration and Imports\n## Simple uncoded transmission\n### Adding spatial correlation\n  \n  \n\n## GPU Configuration and Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#GPU-Configuration-and-Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n```python\n[2]:\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\nfrom sionna.channel import FlatFadingChannel, KroneckerModel\nfrom sionna.channel.utils import exp_corr_mat\nfrom sionna.mimo import lmmse_equalizer\nfrom sionna.mapping import SymbolDemapper, Mapper, Demapper\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\n```\n\n## Simple uncoded transmission<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#Simple-uncoded-transmission\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe will consider point-to-point transmissions from a transmitter with `num_tx_ant` antennas to a receiver with `num_rx_ant` antennas. The transmitter applies no precoding and sends independent data stream from each antenna.\n    \nLet us now generate a batch of random transmit vectors of random 16QAM symbols:\n\n```python\n[3]:\n```\n\n```python\nnum_tx_ant = 4\nnum_rx_ant = 16\nnum_bits_per_symbol = 4\nbatch_size = 1024\nqam_source = QAMSource(num_bits_per_symbol)\nx = qam_source([batch_size, num_tx_ant])\nprint(x.shape)\n```\n\n\n```python\n(1024, 4)\n```\n\n    \nNext, we will create an instance of the `FlatFadingChannel` class to simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`. As we will need knowledge of the channel realizations for detection, we activate the `return_channel` flag.\n\n```python\n[4]:\n```\n\n```python\nchannel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\nno = 0.2 # Noise variance of the channel\n# y and h are the channel output and channel realizations, respectively.\ny, h = channel([x, no])\nprint(y.shape)\nprint(h.shape)\n```\n\n\n```python\n(1024, 16)\n(1024, 16, 4)\n```\n\n    \nUsing the perfect channel knowledge, we can now implement an LMMSE equalizer to compute soft-symbols. The noise covariance matrix in this example is just a scaled identity matrix which we need to provide to the `lmmse_equalizer`.\n\n```python\n[5]:\n```\n\n```python\ns = tf.cast(no*tf.eye(num_rx_ant, num_rx_ant), y.dtype)\nx_hat, no_eff = lmmse_equalizer(y, h, s)\n```\n\n    \nLet us know have a look at the transmitted and received constellations:\n\n```python\n[6]:\n```\n\n```python\nplt.axes().set_aspect(1.0)\nplt.scatter(np.real(x_hat), np.imag(x_hat));\nplt.scatter(np.real(x), np.imag(x));\n```\n\n\n    \nAs expected, the soft symbols `x_hat` are scattered around the 16QAM constellation points. The equalizer output `no_eff` provides an estimate of the effective noise variance for each soft-symbol.\n\n```python\n[7]:\n```\n\n```python\nprint(no_eff.shape)\n```\n\n\n```python\n(1024, 4)\n```\n\n    \nOne can confirm that this estimate is correct by comparing the MSE between the transmitted and equalized symbols against the average estimated effective noise variance:\n\n```python\n[8]:\n```\n\n```python\nnoise_var_eff = np.var(x-x_hat)\nnoise_var_est = np.mean(no_eff)\nprint(noise_var_eff)\nprint(noise_var_est)\n```\n\n\n```python\n0.016722694\n0.016684469\n```\n\n    \nThe last step is to make hard decisions on the symbols and compute the SER:\n\n```python\n[9]:\n```\n\n```python\nsymbol_demapper = SymbolDemapper(\"qam\", num_bits_per_symbol, hard_out=True)\n# Get symbol indices for the transmitted symbols\nx_ind = symbol_demapper([x, no])\n# Get symbol indices for the received soft-symbols\nx_ind_hat = symbol_demapper([x_hat, no])\ncompute_ser(x_ind, x_ind_hat)\n```\n```python\n[9]:\n```\n```python\n<tf.Tensor: shape=(), dtype=float64, numpy=0.002197265625>\n```\n### Adding spatial correlation<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#Adding-spatial-correlation\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIt is very easy add spatial correlation to the `FlatFadingChannel` using the `SpatialCorrelation` class. We can, e.g., easily setup a Kronecker (`KroneckerModel`) (or two-sided) correlation model using exponetial correlation matrices (`exp_corr_mat`).\n\n```python\n[10]:\n```\n\n```python\n# Create transmit and receive correlation matrices\nr_tx = exp_corr_mat(0.4, num_tx_ant)\nr_rx = exp_corr_mat(0.9, num_rx_ant)\n# Add the spatial correlation model to the channel\nchannel.spatial_corr = KroneckerModel(r_tx, r_rx)\n```\n\n    \nNext, we can validate that the channel model applies the desired spatial correlation by creating a large batch of channel realizations from which we compute the empirical transmit and receiver covariance matrices:\n\n```python\n[11]:\n```\n\n```python\nh = channel.generate(1000000)\n# Compute empirical covariance matrices\nr_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/num_rx_ant\nr_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/num_tx_ant\n# Test that the empirical results match the theory\nassert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\nassert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n```\n\n    \nNow, we can transmit the same symbols `x` over the channel with spatial correlation and compute the SER:\n\n```python\n[12]:\n```\n\n```python\ny, h = channel([x, no])\nx_hat, no_eff = lmmse_equalizer(y, h, s)\nx_ind_hat = symbol_demapper([x_hat, no])\ncompute_ser(x_ind, x_ind_hat)\n```\n```python\n[12]:\n```\n```python\n<tf.Tensor: shape=(), dtype=float64, numpy=0.115234375>\n```\n\n    \nThe result cleary show the negative effect of spatial correlation in this setting. You can play around with the `a` parameter defining the exponential correlation matrices and see its impact on the SER.\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Basic MIMO Simulations<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#Basic-MIMO-Simulations\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this notebook, you will learn how to setup simulations of MIMO transmissions over a flat-fading channel.\n    \nHere is a schematic diagram of the system model with all required components:\n    \n    \nYou will learn how to:\n \n- Use the FastFadingChannel class\n- Apply spatial antenna correlation\n- Implement LMMSE detection with perfect channel knowledge\n- Run BER/SER simulations\n\n    \nWe will first walk through the configuration of all components of the system model, before building a general Keras model which will allow you to run efficiently simulations with different parameter settings.\n\n# Table of Content\n## GPU Configuration and Imports\n## Extension to channel coding\n### BER simulations using a Keras model\n  \n  \n\n## GPU Configuration and Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#GPU-Configuration-and-Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n```python\n[2]:\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\nfrom sionna.channel import FlatFadingChannel, KroneckerModel\nfrom sionna.channel.utils import exp_corr_mat\nfrom sionna.mimo import lmmse_equalizer\nfrom sionna.mapping import SymbolDemapper, Mapper, Demapper\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\n```\n\n## Extension to channel coding<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#Extension-to-channel-coding\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nSo far, we have simulated uncoded symbol transmissions. With a few lines of additional code, we can extend what we have done to coded BER simulations. We need the following additional components:\n\n```python\n[13]:\n```\n\n```python\nn = 1024 # codeword length\nk = 512  # number of information bits per codeword\ncoderate = k/n # coderate\nbatch_size = 32\nbinary_source = BinarySource()\nencoder = LDPC5GEncoder(k, n)\ndecoder = LDPC5GDecoder(encoder, hard_out=True)\nmapper = Mapper(\"qam\", num_bits_per_symbol)\ndemapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n```\n\n    \nNext we need to generate random QAM symbols through mapping of coded bits. Reshaping is required to bring `x` into the needed shape.\n\n```python\n[14]:\n```\n\n```python\nb = binary_source([batch_size, num_tx_ant, k])\nc = encoder(b)\nx = mapper(c)\nx_ind = symbol_demapper([x, no]) # Get symbol indices for SER computation later on\nshape = tf.shape(x)\nx = tf.reshape(x, [-1, num_tx_ant])\nprint(x.shape)\n```\n\n\n```python\n(8192, 4)\n```\n\n    \nWe will now transmit the symbols over the channel:\n\n```python\n[15]:\n```\n\n```python\ny, h = channel([x, no])\nx_hat, no_eff = lmmse_equalizer(y, h, s)\n```\n\n    \nAnd then demap the symbols to LLRs prior to decoding them. Note that we need to bring `x_hat` and `no_eff` back to the desired shape for decoding.\n\n```python\n[16]:\n```\n\n```python\nx_ind_hat.shape\n```\n```python\n[16]:\n```\n```python\nTensorShape([1024, 4])\n```\n```python\n[17]:\n```\n\n```python\nx_hat = tf.reshape(x_hat, shape)\nno_eff = tf.reshape(no_eff, shape)\nllr = demapper([x_hat, no_eff])\nb_hat = decoder(llr)\nx_ind_hat = symbol_demapper([x_hat, no])\nber = compute_ber(b, b_hat).numpy()\nprint(\"Uncoded SER : {}\".format(compute_ser(x_ind, x_ind_hat)))\nprint(\"Coded BER : {}\".format(compute_ber(b, b_hat)))\n```\n\n\n```python\nUncoded SER : 0.1219482421875\nCoded BER : 0.0\n```\n\n    \nDespite the fairly high SER, the BER is very low, thanks to the channel code.\n\n### BER simulations using a Keras model<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html#BER-simulations-using-a-Keras-model\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nNext, we will wrap everything that we have done so far in a Keras model for convenient BER simulations and comparison of model parameters. Note that we use the `@tf.function(jit_compile=True)` decorator which will speed-up the simulations tremendously. See <a class=\"reference external\" href=\"https://www.tensorflow.org/guide/function\">https://www.tensorflow.org/guide/function</a> for further information. You need to enable the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat\">sionna.config.xla_compat</a> feature prior to executing the model.\n\n```python\n[18]:\n```\n\n```python\nsionna.config.xla_compat=True\nclass Model(tf.keras.Model):\n    def __init__(self, spatial_corr=None):\n        super().__init__()\n        self.n = 1024\n        self.k = 512\n        self.coderate = self.k/self.n\n        self.num_bits_per_symbol = 4\n        self.num_tx_ant = 4\n        self.num_rx_ant = 16\n        self.binary_source = BinarySource()\n        self.encoder = LDPC5GEncoder(self.k, self.n)\n        self.mapper = Mapper(\"qam\", self.num_bits_per_symbol)\n        self.demapper = Demapper(\"app\", \"qam\", self.num_bits_per_symbol)\n        self.decoder = LDPC5GDecoder(self.encoder, hard_out=True)\n        self.channel = FlatFadingChannel(self.num_tx_ant,\n                                         self.num_rx_ant,\n                                         spatial_corr=spatial_corr,\n                                         add_awgn=True,\n                                         return_channel=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db):\n        b = self.binary_source([batch_size, self.num_tx_ant, self.k])\n        c = self.encoder(b)\n        x = self.mapper(c)\n        shape = tf.shape(x)\n        x = tf.reshape(x, [-1, self.num_tx_ant])\n        no = ebnodb2no(ebno_db, self.num_bits_per_symbol, self.coderate)\n        no *= np.sqrt(self.num_rx_ant)\n        y, h = self.channel([x, no])\n        s = tf.complex(no*tf.eye(self.num_rx_ant, self.num_rx_ant), 0.0)\n        x_hat, no_eff = lmmse_equalizer(y, h, s)\n        x_hat = tf.reshape(x_hat, shape)\n        no_eff = tf.reshape(no_eff, shape)\n        llr = self.demapper([x_hat, no_eff])\n        b_hat = self.decoder(llr)\n        return b,  b_hat\n```\n\n    \nWe can now instantiate different version of this model and use the `PlotBer` class for easy Monte-Carlo simulations.\n\n```python\n[19]:\n```\n\n```python\nber_plot = PlotBER()\n```\n```python\n[20]:\n```\n\n```python\nmodel1 = Model()\nber_plot.simulate(model1,\n        np.arange(-2.5, 0.25, 0.25),\n        batch_size=4096,\n        max_mc_iter=1000,\n        num_target_block_errors=100,\n        legend=\"Uncorrelated\",\n        show_fig=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -2.5 | 1.1113e-01 | 9.1742e-01 |      932264 |     8388608 |        15031 |       16384 |         6.7 |reached target block errors\n    -2.25 | 7.9952e-02 | 7.8546e-01 |      670690 |     8388608 |        12869 |       16384 |         0.2 |reached target block errors\n     -2.0 | 5.0242e-02 | 5.9320e-01 |      421458 |     8388608 |         9719 |       16384 |         0.2 |reached target block errors\n    -1.75 | 2.6710e-02 | 3.7158e-01 |      224061 |     8388608 |         6088 |       16384 |         0.2 |reached target block errors\n     -1.5 | 1.1970e-02 | 1.9104e-01 |      100415 |     8388608 |         3130 |       16384 |         0.2 |reached target block errors\n    -1.25 | 4.6068e-03 | 7.8186e-02 |       38645 |     8388608 |         1281 |       16384 |         0.2 |reached target block errors\n     -1.0 | 1.2861e-03 | 2.5818e-02 |       10789 |     8388608 |          423 |       16384 |         0.2 |reached target block errors\n    -0.75 | 2.7883e-04 | 7.8735e-03 |        2339 |     8388608 |          129 |       16384 |         0.2 |reached target block errors\n     -0.5 | 8.5314e-05 | 2.2990e-03 |        2147 |    25165824 |          113 |       49152 |         0.7 |reached target block errors\n    -0.25 | 1.2082e-05 | 3.1738e-04 |        2027 |   167772160 |          104 |      327680 |         4.4 |reached target block errors\n      0.0 | 1.9351e-06 | 7.1681e-05 |        1396 |   721420288 |          101 |     1409024 |        19.0 |reached target block errors\n```\n```python\n[21]:\n```\n\n```python\nr_tx = exp_corr_mat(0.4, num_tx_ant)\nr_rx = exp_corr_mat(0.7, num_rx_ant)\nmodel2 = Model(KroneckerModel(r_tx, r_rx))\nber_plot.simulate(model2,\n        np.arange(0,2.6,0.25),\n        batch_size=4096,\n        max_mc_iter=1000,\n        num_target_block_errors=200,\n        legend=\"Kronecker model\");\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 7.2249e-02 | 7.1844e-01 |      606070 |     8388608 |        11771 |       16384 |         4.9 |reached target block errors\n     0.25 | 4.7019e-02 | 5.4126e-01 |      394421 |     8388608 |         8868 |       16384 |         0.2 |reached target block errors\n      0.5 | 2.7080e-02 | 3.5498e-01 |      227161 |     8388608 |         5816 |       16384 |         0.2 |reached target block errors\n     0.75 | 1.3981e-02 | 2.0380e-01 |      117280 |     8388608 |         3339 |       16384 |         0.2 |reached target block errors\n      1.0 | 6.1550e-03 | 9.6802e-02 |       51632 |     8388608 |         1586 |       16384 |         0.2 |reached target block errors\n     1.25 | 2.2970e-03 | 4.0100e-02 |       19269 |     8388608 |          657 |       16384 |         0.2 |reached target block errors\n      1.5 | 7.9966e-04 | 1.4282e-02 |        6708 |     8388608 |          234 |       16384 |         0.2 |reached target block errors\n     1.75 | 2.4907e-04 | 4.5166e-03 |        6268 |    25165824 |          222 |       49152 |         0.7 |reached target block errors\n      2.0 | 7.0466e-05 | 1.3767e-03 |        5320 |    75497472 |          203 |      147456 |         2.0 |reached target block errors\n     2.25 | 1.4114e-05 | 3.0670e-04 |        4736 |   335544320 |          201 |      655360 |         9.0 |reached target block errors\n      2.5 | 2.8881e-06 | 7.0971e-05 |        4167 |  1442840576 |          200 |     2818048 |        38.7 |reached target block errors\n```\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Optical Channel with Lumped Amplification<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Optical-Channel-with-Lumped-Amplification\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this notebook, you will learn how to simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, so-called Erbium Doped Fiber Amplifiers (EDFA), as shown in the Figure below. We assume a <em>standard single mode fiber</em> (S-SMF) and denote the fiber length between two amplifiers by $\\ell_\\text{span}$.\n    \n    \nLet $G$ denote the amplifier gain and $F$ the noise figure of each EDFA.\n    \nAs we focus on the optical channel and not the corresponding signal processing, the transmitter directly generates the optical signal. Hence, all components that, in practice, are required to generate the optical signal given an electrical control voltage (e.g., the Mach-Zehnder-Modulator (MZM)) are assumed to be ideal or are neglected. The same holds on the receiver side, where the photodiode that would add shot noise is neglected.\n    \nTo provide a better understanding of the implemented channel impairments (attenuation, noise, dispersion, nonlinearity) introduced during propagation, those are successively enabled, starting with attenuation.\n\n# Table of Content\n## Setup\n## Attenuation\n## Amplified Spontaneous Emission Noise\n  \n  \n\n## Setup<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Setup\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\nfrom sionna.channel import utils\n```\n```python\n[2]:\n```\n\n```python\nimport tensorflow as tf\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n```python\n[3]:\n```\n\n```python\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sionna.channel import utils\n```\n\n## Impulse Generation<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Impulse-Generation\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nBefore diving into the first channel model, the simulation shall be parametrized and the initial Gaussian impulse\n\n$$\ng(t)=\\sqrt{P_0\\cdot 2^{\\left(-\\left(\\frac{2t}{T_0}\\right)^2\\right)}}\n$$\n    \nis generated. The impulse shall have peak power $P_0$ and a pulse duration of $T_0$. Note that the Gaussian filter is infinitely long, such that $T_0$ is the full width at half-maximum (FWHM) pulse duration.\n    \nFurther, the simulation window is set to $T_\\mathrm{sim}=1000\\,\\mathrm{ps}$ and the sample duration is set to $\\Delta_t=1\\,\\mathrm{ps}$.\n\n```python\n[4]:\n```\n\n```python\n# Simulation parameters\ndtype = tf.complex128  # Simulation accuracy (double)\nt_sim = int(1e4)  # (ps) Simulation time window\nn_sim = int(1e4)  # Number of simulation samples\n# Channel parameters\nn_span = 3\n# Impulse parameters\np_0 = 3e-2  # (W) Peak power of the Gaussian pulse\nt_0 = 50  # (ps) Norm. temporal scaling of the Gaussian pulse\n# Support\ndt = t_sim / n_sim  # (s) sample duration\nt, f = utils.time_frequency_vector(\n    n_sim, dt, dtype=dtype.real_dtype)  # (ps), (THz) Time and frequency vector\n# Generate Gaussian impulse\ng_0 = np.sqrt(p_0 * 2**(-((2.0*t / t_0) ** 2.0)))\ng_0 = tf.cast(g_0, dtype=dtype)\nG_0 = tf.signal.fftshift(\n        tf.abs(\n            tf.cast(dt, dtype) *\n            tf.signal.fft(g_0) /\n            tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n        ) ** 2\n)\n```\n```python\n[5]:\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(g_0.numpy().flatten())**2, '-')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (G_0.numpy().flatten())/np.max(G_0.numpy().flatten()),\n    '-')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted'])\nplt.tight_layout()\nplt.show()\n```\n\n## Attenuation<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Attenuation\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nAttenuation is present in all media including optical fibers. A typical value of $\\alpha=0.046\\,\\mathrm{km}^{-1}$ is used in this notebook. To compensate for this, Erbium doped fiber amplifiers (EDFAs) are required, as shown in the figure at the beginning of this notebook.\n\n## Amplified Spontaneous Emission Noise<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Amplified-Spontaneous-Emission-Noise\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nAn optical channel model contains several sources of noise, e.g., amplified spontaneous emission (ASE) and Rayleigh scattering. However, for this experiment, only ASE noise is implemented. It was shown in [1] that this is the most dominant source of noise.\n    \nAs we assume a discrete lumped amplification, ASE noise is introduced only due to the amplification by the EDFAs. The noise power is given as\n\n$$\nP_\\mathrm{ASE}=\\rho_\\mathrm{ASE}\\cdot f_\\text{sim}=\\frac{1}{2}G F h f_\\text{c}\\cdot f_\\mathrm{sim}\n$$\n    \nand, hence, depends on the gain $G$, the (linear) noise figure $F$, the carrier frequency $f_\\text{c}$, and the simulation bandwidth $f_\\mathrm{sim}$. The intermediate quantitiy $\\rho_\\mathrm{ASE}$ denotes the noise spectral density of the EDFAs and $h$ is Planck\u2019s constant. Usually, not the simulation bandwidth but the captured bandwidth $W$ of the receiver is used. Here, for demonstration purpose, our receiver has an infinite bandwidth that is only\nlimited by the simulation $W=f_\\mathrm{sim}$.\n    \n**Note** that Sionna also provides ideally distributed Raman amplification, where the noise is introduced in a fiber span. This can be enabled by setting `with_amplification` to `True` when instantiating the `SSFM` layer.\n\n### Channel Configuration<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Channel-Configuration\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThe fiber (i.e., <em>SSFM</em>) is implemented using normalized units for distance and time. Hence, it is required that the units of the same kind (time, distance, power) for all parameters ($\\alpha$, $\\beta_2$, \u2026) have to be given with the same unit prefix, e.g., for time use always $\\mathrm{ps}$. This does not only simplify the usage of the SSFM but also prevents from dealing with different orders of magnitude within the SSFM.\n    \nFor our first experiment only ASE noise is considered and, thus, nonlinearity and chromatic dispersion (CD) are disabled. Attenuation is kept enabled such that the amplifiers are required and introduce the noise. The gain is chosen such that the link becomes transparent (input power equals output power).\n\n```python\n[6]:\n```\n\n```python\n# Normalization\nt_norm = 1e-12  # (s) -> (ps) Time normalization\nz_norm = 1e3  # (m) -> (km) Distance normalization\n# Fiber parameters\nf_c = 193.55e12  # (Hz) Abs. Carrier frequency\nlength_sp = 80.0  # (km) Norm. fiber span length\nalpha = 0.046  # (1/km) Norm. fiber attenuation\n# EDFA parameters\ng_edfa = tf.exp(alpha * length_sp)\nf_edfa = 10**(5/10)  # (1) Noise figure\n```\n```python\n[7]:\n```\n\n```python\nspan = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=False,\n            with_nonlinearity=False,\n            dtype=dtype,\n            t_norm=t_norm)\namplifier = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=f_edfa,\n            f_c=f_c,\n            dt=dt * t_norm,  # t_norm is in absolute (not normalized) units\n            dtype=dtype)\ndef lumped_amplification_channel(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(n_span):\n        u = span(u)\n        u = amplifier(u)\n    return u\n```\n\n### Transmission<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Transmission\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nNext, the impulse is transmitted over the channel and the output is visualized.\n\n```python\n[8]:\n```\n\n```python\nx = g_0\ny = lumped_amplification_channel(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\n```\n```python\n[9]:\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten())/np.max(X.numpy().flatten()),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten())/np.max(Y.numpy().flatten()),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\n    \nAs can be seen, attenuation is completely compensated by the EDFAs. However, they introduce significant noise.\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Optical Channel with Lumped Amplification<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Optical-Channel-with-Lumped-Amplification\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this notebook, you will learn how to simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, so-called Erbium Doped Fiber Amplifiers (EDFA), as shown in the Figure below. We assume a <em>standard single mode fiber</em> (S-SMF) and denote the fiber length between two amplifiers by $\\ell_\\text{span}$.\n    \n    \nLet $G$ denote the amplifier gain and $F$ the noise figure of each EDFA.\n    \nAs we focus on the optical channel and not the corresponding signal processing, the transmitter directly generates the optical signal. Hence, all components that, in practice, are required to generate the optical signal given an electrical control voltage (e.g., the Mach-Zehnder-Modulator (MZM)) are assumed to be ideal or are neglected. The same holds on the receiver side, where the photodiode that would add shot noise is neglected.\n    \nTo provide a better understanding of the implemented channel impairments (attenuation, noise, dispersion, nonlinearity) introduced during propagation, those are successively enabled, starting with attenuation.\n\n# Table of Content\n## Chromatic Dispersion\n## Kerr Nonlinearity\n  \n  \n\n## Chromatic Dispersion<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Chromatic-Dispersion\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nAfter having seen how the noise distorts the original Gaussian impulse, we can now enable the next linear effect, which is chromatic dispersion (CD). Regarding the nonlinear Schr\u00f6dinger equation that describes the propagation of an optical signal, the impact of CD is parametrized by the group velocity dispersion (GVD) parameter $\\beta_2$, where $\\beta_2=-21.67\\,\\mathrm{ps}^2\\mathrm{km}^{-1}$ is a typical choice.\n\n### Channel Configuration<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#id1\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nBesides the present parameters we now set $\\beta_2$. For a better understanding of CD we disable the noise (`EDFA.f` `=` `0`) from the previous section.\n\n```python\n[10]:\n```\n\n```python\nbeta_2 = -21.67  # (ps^2/km) Norm. group velocity dispersion\n```\n```python\n[11]:\n```\n\n```python\nspan_cd = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=True,\n            with_nonlinearity=False,\n            dtype=dtype,\n            t_norm=t_norm)\namplifier_cd = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=0,\n            f_c=f_c,\n            dt=dt * t_norm,\n            dtype=dtype)\n\ndef lumped_amplification_channel_cd(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(n_span):\n        u = span_cd(u)\n        u = amplifier_cd(u)\n    return u\n```\n\n### Transmission<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#id2\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe now transmit the previously generated Gaussian impulse over the optical fiber and compare the received signal with the transmitted impulse.\n\n```python\n[12]:\n```\n\n```python\nx = g_0  # previously generated Gaussian impulse\ny = lumped_amplification_channel_cd(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nX_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(x)))\nY_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(y)))\n```\n```python\n[13]:\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-250, 250)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten())/np.max(X.numpy().flatten()),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten())/np.max(Y.numpy().flatten()),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\n    \nCompared to the transmit impulse the received one has significantly broadened in time. The absolute value of the spectrum, nevertheless, stayed the same. By plotting the phase of the received signal one can see the typical parabolic shift.\n\n```python\n[14]:\n```\n\n```python\nfig, (ax1) = plt.subplots(1, 1, tight_layout=True)\nax1.plot(t.numpy().flatten(), np.angle(x.numpy().flatten()), '-')\nax1.plot(t.numpy().flatten(), np.angle(y.numpy().flatten()), '--')\nax1.set_xlim(-750, 750)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\n## Kerr Nonlinearity<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Kerr-Nonlinearity\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nLast, we depict the Kerr nonlinearity and, for a better understanding, disable all previous impairments. This nonlinear effect applies a phase shift to the transmitted signal depending on its instantaneous power. Hence, we should see a phase that, in contrast to the phase of the original signal which is zero, follows the (inverse) absolute value of the impulse.\n    \n**Note:** Only the interaction between Kerr nonlinearity and CD requires an SSFM for fiber simulation. Otherwise (as done so far), the transfer function of the individual effect is just a single multiplication (in time- or Fourier-domain, respectively).\n\n### Channel configuration<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Channel-configuration\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nSimilarly to the definition of CD, we specify a typical value for $\\gamma=1.27\\,\\mathrm{\\frac{1}{km W}}$.\n\n```python\n[15]:\n```\n\n```python\ngamma = 1.27  # (1/W/km) Nonlinearity coefficient\n```\n```python\n[16]:\n```\n\n```python\nspan_nl = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=False,\n            with_nonlinearity=True,\n            dtype=dtype, t_norm=t_norm)\namplifier_nl = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=0,\n            f_c=f_c,\n            dt=dt * t_norm,\n            dtype=dtype)\n\ndef lumped_amplification_channel_nl(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(n_span):\n        u = span_nl(u)\n        u = amplifier_nl(u)\n    return u\n```\n\n### Transmission<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#id4\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe now transmit the same Gaussian impulse again over the optical fiber where only Kerr nonlinearity is activated.\n\n```python\n[17]:\n```\n\n```python\nx = g_0\ny = lumped_amplification_channel_nl(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nX_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(x)))\nY_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(y)))\n```\n```python\n[18]:\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten())/np.max(X.numpy().flatten()),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten())/np.max(Y.numpy().flatten()),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\n\nplt.show()\n```\n\n\n    \nAs shown in the previous plot the (isolated) Kerr nonlinearity does not affect the absolute value of the signal\u2019s amplitude but only shifts the phase (see below).\n    \nFurther, the bandwidth of the transmit signal was slightly increased.\n    \n**Hint**: Increasing the peak power $p_0$ of the transmitted impuls increases the impact of the Kerr nonlinearity.\n\n```python\n[19]:\n```\n\n```python\nfig, (ax1) = plt.subplots(1, 1, tight_layout=True)\nax1.plot(t.numpy().flatten(), np.angle(x.numpy().flatten()), '-')\nax1.plot(t.numpy().flatten(), np.angle(y.numpy().flatten()), '--')\nax1.set_xlim(-750, 750)\nax1.set_xlabel(\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Optical Channel with Lumped Amplification<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Optical-Channel-with-Lumped-Amplification\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this notebook, you will learn how to simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, so-called Erbium Doped Fiber Amplifiers (EDFA), as shown in the Figure below. We assume a <em>standard single mode fiber</em> (S-SMF) and denote the fiber length between two amplifiers by $\\ell_\\text{span}$.\n    \n    \nLet $G$ denote the amplifier gain and $F$ the noise figure of each EDFA.\n    \nAs we focus on the optical channel and not the corresponding signal processing, the transmitter directly generates the optical signal. Hence, all components that, in practice, are required to generate the optical signal given an electrical control voltage (e.g., the Mach-Zehnder-Modulator (MZM)) are assumed to be ideal or are neglected. The same holds on the receiver side, where the photodiode that would add shot noise is neglected.\n    \nTo provide a better understanding of the implemented channel impairments (attenuation, noise, dispersion, nonlinearity) introduced during propagation, those are successively enabled, starting with attenuation.\n\n# Table of Content\n## Split-Step Fourier Method\n## References\n  \n  \n\n## Split-Step Fourier Method<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#Split-Step-Fourier-Method\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nLast, we perform the true SSFM to simulate the impairments (ASE noise, CD, and Kerr nonlinearity) jointly. As this is computationally complex, we compile the channel model before its execution by adding the `tf.function` decorator.\n\n### Channel Configuration<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#id5\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nKeeping the former configuration, we only have to increase the number of SSFM simulation steps.\n\n```python\n[20]:\n```\n\n```python\nn_ssfm = 160  # number of SSFM simulation steps\n```\n```python\n[21]:\n```\n\n```python\nspan_ssfm = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            gamma=gamma,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            n_ssfm=n_ssfm,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=True,\n            with_nonlinearity=True,\n            dtype=dtype,\n            t_norm=t_norm)\namplifier_ssfm = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=0,\n            f_c=f_c,\n            dt=dt * t_norm,\n            dtype=dtype)\n@tf.function\ndef lumped_amplification_channel_ssfm(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(1):\n        u = span_ssfm(u)\n        u = amplifier_ssfm(u)\n    return u\n```\n\n### Transmission<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#id6\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe transmit the Gaussian impulse over the optical fiber. However, we have now enabled ASE noise, CD, and Kerr nonlinearity.\n\n```python\n[22]:\n```\n\n```python\nx = g_0\ny = lumped_amplification_channel_ssfm(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nX_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(x)))\nY_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(y)))\n```\n```python\n[23]:\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten()/np.max(X.numpy().flatten())),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten()/np.max(Y.numpy().flatten())),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n```python\n[24]:\n```\n\n```python\nfig, (ax1) = plt.subplots(1, 1, tight_layout=True)\nax1.plot(t.numpy().flatten(), np.angle(x.numpy().flatten()), '-')\nax1.plot(t.numpy().flatten(), np.angle(y.numpy().flatten()), '--')\nax1.set_xlim(-500, 500)\nax1.set_xlabel(\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\n    \nThe most interesting observation that one can make here is that the spectrum of the received signal is compressed. This is in contrast to the expected Kerr nonlinearity-induced spectral broadening, and shows that joint application of the fiber effects may result in completely different observations compared to the isolated investigation.\n    \nWhat we can see here, however, is that the Gaussian input impulse is transformed to a higher-order Soliton during propagation. Those require a joint CD and Kerr nonlinearity to exist.\n## References<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Optical_Lumped_Amplification_Channel.html#References\" title=\"Permalink to this headline\">\uf0c1</a>\n    \n[1] Ren\u00e9-Jean Essiambre, Gerhard Kramer, Peter J. Winzer, Gerard J. Foschini, and Bernhard Goebel. \u201eCapacity Limits of Optical Fiber Networks\u201c. Journal of Lightwave Technology 28, Nr. 4, pp 662\u2013701, February 2010.\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 1: Getting Started with Sionna<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Part-1:-Getting-Started-with-Sionna\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- **Part I: Getting started with Sionna**\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n\n# Table of Content\n## Imports & Basics\n## Sionna Data-flow and Design Paradigms\n  \n  \n\n## Imports & Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Imports-&-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\n# also try %matplotlib widget\nimport matplotlib.pyplot as plt\n# for performance measurements\nimport time\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n    \nWe can now access Sionna functions within the `sn` namespace.\n    \n**Hint**: In Jupyter notebooks, you can run bash commands with `!`.\n\n```python\n[2]:\n```\n\n```python\n!nvidia-smi\n```\n\n\n```python\nTue Mar 15 14:47:45 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 30%   51C    P8    23W / 350W |     53MiB / 24265MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   33C    P8    24W / 350W |      8MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```\n## Sionna Data-flow and Design Paradigms<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Sionna-Data-flow-and-Design-Paradigms\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nSionna inherently parallelizes simulations via <em>batching</em>, i.e., each element in the batch dimension is simulated independently.\n    \nThis means the first tensor dimension is always used for <em>inter-frame</em> parallelization similar to an outer <em>for-loop</em> in Matlab/NumPy simulations, but operations can be operated in parallel.\n    \nTo keep the dataflow efficient, Sionna follows a few simple design principles:\n \n- Signal-processing components are implemented as an individual <a class=\"reference external\" href=\"https://keras.io/api/layers/\">Keras layer</a>.\n- `tf.float32` is used as preferred datatype and `tf.complex64` for complex-valued datatypes, respectively.\nThis allows simpler re-use of components (e.g., the same scrambling layer can be used for binary inputs and LLR-values).\n- `tf.float64`/`tf.complex128` are available when high precision is needed.\n- Models can be developed in <em>eager mode</em> allowing simple (and fast) modification of system parameters.\n- Number crunching simulations can be executed in the faster <em>graph mode</em> or even <em>XLA</em> acceleration (experimental) is available for most components.\n- Whenever possible, components are automatically differentiable via <a class=\"reference external\" href=\"https://www.tensorflow.org/guide/autodiff\">auto-grad</a> to simplify the deep learning design-flow.\n- Code is structured into sub-packages for different tasks such as channel coding, mapping,\u2026 (see <a class=\"reference external\" href=\"http://nvlabs.github.io/sionna/api/sionna.html\">API documentation</a> for details).\n\n    \nThese paradigms simplify the re-useability and reliability of our components for a wide range of communications related applications.\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 1: Getting Started with Sionna<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Part-1:-Getting-Started-with-Sionna\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- **Part I: Getting started with Sionna**\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n\n# Table of Content\n## Imports & Basics\n## Hello, Sionna!\n  \n  \n\n## Imports & Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Imports-&-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\n# also try %matplotlib widget\nimport matplotlib.pyplot as plt\n# for performance measurements\nimport time\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n    \nWe can now access Sionna functions within the `sn` namespace.\n    \n**Hint**: In Jupyter notebooks, you can run bash commands with `!`.\n\n```python\n[2]:\n```\n\n```python\n!nvidia-smi\n```\n\n\n```python\nTue Mar 15 14:47:45 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 30%   51C    P8    23W / 350W |     53MiB / 24265MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   33C    P8    24W / 350W |      8MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```\n## Hello, Sionna!<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Hello,-Sionna!\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nLet\u2019s start with a very simple simulation: Transmitting QAM symbols over an AWGN channel. We will implement the system shown in the figure below.\n    \n    \nWe will use upper case for naming simulation parameters that are used throughout this notebook\n    \nEvery layer needs to be initialized once before it can be used.\n    \n**Tip**: Use the <a class=\"reference external\" href=\"http://nvlabs.github.io/sionna/api/sionna.html\">API documentation</a> to find an overview of all existing components. You can directly access the signature and the docstring within jupyter via `Shift+TAB`.\n    \n<em>Remark</em>: Most layers are defined to be complex-valued.\n    \nWe first need to create a QAM constellation.\n\n```python\n[3]:\n```\n\n```python\nNUM_BITS_PER_SYMBOL = 2 # QPSK\nconstellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\nconstellation.show();\n```\n\n\n    \n**Task:** Try to change the modulation order, e.g., to 16-QAM.\n    \nWe then need to setup a mapper to map bits into constellation points. The mapper takes as parameter the constellation.\n    \nWe also need to setup a corresponding demapper to compute log-likelihood ratios (LLRs) from received noisy samples.\n\n```python\n[4]:\n```\n\n```python\nmapper = sn.mapping.Mapper(constellation=constellation)\n# The demapper uses the same constellation object as the mapper\ndemapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n```\n\n    \n**Tip**: You can access the signature+docstring via `?` command and print the complete class definition via `??` operator.\n    \nObviously, you can also access the source code via <a class=\"reference external\" href=\"https://github.com/nvlabs/sionna/\">https://github.com/nvlabs/sionna/</a>.\n\n```python\n[5]:\n```\n\n```python\n# print class definition of the Constellation class\nsn.mapping.Mapper??\n```\n\n\n```python\nInit signature: sn.mapping.Mapper(*args, **kwargs)\nSource:\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r&#34;&#34;&#34;\n    Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)\n    Maps binary tensors to points of a constellation.\n    This class defines a layer that maps a tensor of binary values\n    to a tensor of points from a provided constellation.\n    Parameters\n    ----------\n    constellation_type : One of [&#34;qam&#34;, &#34;pam&#34;, &#34;custom&#34;], str\n        For &#34;custom&#34;, an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [&#34;qam&#34;, &#34;pam&#34;].\n    constellation :  Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or\n        `None`. In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n    dtype : One of [tf.complex64, tf.complex128], tf.DType\n        The output dtype. Defaults to tf.complex64.\n    Input\n    -----\n    : [..., n], tf.float or tf.int\n        Tensor with with binary entries.\n    Output\n    ------\n    : [...,n/Constellation.num_bits_per_symbol], tf.complex\n        The mapped constellation symbols.\n    Note\n    ----\n    The last input dimension must be an integer multiple of the\n    number of bits per constellation symbol.\n    &#34;&#34;&#34;\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 dtype=tf.complex64,\n                 **kwargs\n                ):\n        super().__init__(dtype=dtype, **kwargs)\n        assert dtype in [tf.complex64, tf.complex128],\\\n            &#34;dtype must be tf.complex64 or tf.complex128&#34;\n        #self._dtype = dtype\n        #print(dtype, self._dtype)\n        if constellation is not None:\n            assert constellation_type in [None, &#34;custom&#34;], \\\n                &#34;&#34;&#34;`constellation_type` must be &#34;custom&#34;.&#34;&#34;&#34;\n            assert num_bits_per_symbol in \\\n                     [None, constellation.num_bits_per_symbol], \\\n                &#34;&#34;&#34;`Wrong value of `num_bits_per_symbol.`&#34;&#34;&#34;\n            self._constellation = constellation\n        else:\n            assert constellation_type in [&#34;qam&#34;, &#34;pam&#34;], \\\n                &#34;Wrong constellation type.&#34;\n            assert num_bits_per_symbol is not None, \\\n                &#34;`num_bits_per_symbol` must be provided.&#34;\n            self._constellation = Constellation(constellation_type,\n                                                num_bits_per_symbol,\n                                                dtype=self._dtype)\n        self._binary_base = 2**tf.constant(\n                        range(self.constellation.num_bits_per_symbol-1,-1,-1))\n    @property\n    def constellation(self):\n        &#34;&#34;&#34;The Constellation used by the Mapper.&#34;&#34;&#34;\n        return self._constellation\n    def call(self, inputs):\n        tf.debugging.assert_greater_equal(tf.rank(inputs), 2,\n            message=&#34;The input must have at least rank 2&#34;)\n        # Reshape inputs to the desired format\n        new_shape = [-1] + inputs.shape[1:-1].as_list() + \\\n           [int(inputs.shape[-1] / self.constellation.num_bits_per_symbol),\n            self.constellation.num_bits_per_symbol]\n        inputs_reshaped = tf.cast(tf.reshape(inputs, new_shape), tf.int32)\n        # Convert the last dimension to an integer\n        int_rep = tf.reduce_sum(inputs_reshaped * self._binary_base, axis=-1)\n        # Map integers to constellation symbols\n        x = tf.gather(self.constellation.points, int_rep, axis=0)\n        return x\nFile:           ~/.local/lib/python3.8/site-packages/sionna/mapping.py\nType:           type\nSubclasses:\n```\n\n    \nAs can be seen, the `Mapper` class inherits from `Layer`, i.e., implements a Keras layer.\n    \nThis allows to simply built complex systems by using the <a class=\"reference external\" href=\"https://keras.io/guides/functional_api/\">Keras functional API</a> to stack layers.\n    \nSionna provides as utility a binary source to sample uniform i.i.d. bits.\n\n```python\n[6]:\n```\n\n```python\nbinary_source = sn.utils.BinarySource()\n```\n\n    \nFinally, we need the AWGN channel.\n\n```python\n[7]:\n```\n\n```python\nawgn_channel = sn.channel.AWGN()\n```\n\n    \nSionna provides a utility function to compute the noise power spectral density ratio $N_0$ from the energy per bit to noise power spectral density ratio $E_b/N_0$ in dB and a variety of parameters such as the coderate and the nunber of bits per symbol.\n\n```python\n[8]:\n```\n\n```python\nno = sn.utils.ebnodb2no(ebno_db=10.0,\n                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                        coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\n```\n\n    \nWe now have all the components we need to transmit QAM symbols over an AWGN channel.\n    \nSionna natively supports multi-dimensional tensors.\n    \nMost layers operate at the last dimension and can have arbitrary input shapes (preserved at output).\n\n```python\n[9]:\n```\n\n```python\nBATCH_SIZE = 64 # How many examples are processed by Sionna in parallel\nbits = binary_source([BATCH_SIZE,\n                      1024]) # Blocklength\nprint(\"Shape of bits: \", bits.shape)\nx = mapper(bits)\nprint(\"Shape of x: \", x.shape)\ny = awgn_channel([x, no])\nprint(\"Shape of y: \", y.shape)\nllr = demapper([y, no])\nprint(\"Shape of llr: \", llr.shape)\n```\n\n\n```python\nShape of bits:  (64, 1024)\nShape of x:  (64, 512)\nShape of y:  (64, 512)\nShape of llr:  (64, 1024)\n```\n\n    \nIn <em>Eager</em> mode, we can directly access the values of each tensor. This simplify debugging.\n\n```python\n[10]:\n```\n\n```python\nnum_samples = 8 # how many samples shall be printed\nnum_symbols = int(num_samples/NUM_BITS_PER_SYMBOL)\nprint(f\"First {num_samples} transmitted bits: {bits[0,:num_samples]}\")\nprint(f\"First {num_symbols} transmitted symbols: {np.round(x[0,:num_symbols], 2)}\")\nprint(f\"First {num_symbols} received symbols: {np.round(y[0,:num_symbols], 2)}\")\nprint(f\"First {num_samples} demapped llrs: {np.round(llr[0,:num_samples], 2)}\")\n```\n\n\n```python\nFirst 8 transmitted bits: [0. 1. 1. 1. 1. 0. 1. 0.]\nFirst 4 transmitted symbols: [ 0.71-0.71j -0.71-0.71j -0.71+0.71j -0.71+0.71j]\nFirst 4 received symbols: [ 0.65-0.61j -0.62-0.69j -0.6 +0.72j -0.86+0.63j]\nFirst 8 demapped llrs: [-36.65  34.36  35.04  38.83  33.96 -40.5   48.47 -35.65]\n```\n\n    \nLet\u2019s visualize the received noisy samples.\n\n```python\n[11]:\n```\n\n```python\nplt.figure(figsize=(8,8))\nplt.axes().set_aspect(1)\nplt.grid(True)\nplt.title('Channel output')\nplt.xlabel('Real Part')\nplt.ylabel('Imaginary Part')\nplt.scatter(tf.math.real(y), tf.math.imag(y))\nplt.tight_layout()\n```\n\n\n    \n**Task:** One can play with the SNR to visualize the impact on the received samples.\n    \n**Advanced Task:** Compare the LLR distribution for \u201capp\u201d demapping with \u201cmaxlog\u201d demapping. The <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html\">Bit-Interleaved Coded Modulation</a> example notebook can be helpful for this task.\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 1: Getting Started with Sionna<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Part-1:-Getting-Started-with-Sionna\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- **Part I: Getting started with Sionna**\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n\n# Table of Content\n## Imports & Basics\n## Communication Systems as Keras Models\n  \n  \n\n## Imports & Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Imports-&-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\n# also try %matplotlib widget\nimport matplotlib.pyplot as plt\n# for performance measurements\nimport time\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n    \nWe can now access Sionna functions within the `sn` namespace.\n    \n**Hint**: In Jupyter notebooks, you can run bash commands with `!`.\n\n```python\n[2]:\n```\n\n```python\n!nvidia-smi\n```\n\n\n```python\nTue Mar 15 14:47:45 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 30%   51C    P8    23W / 350W |     53MiB / 24265MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   33C    P8    24W / 350W |      8MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```\n## Communication Systems as Keras Models<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Communication-Systems-as-Keras-Models\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIt is typically more convenient to wrap a Sionna-based communication system into a <a class=\"reference external\" href=\"https://keras.io/api/models/model/\">Keras models</a>.\n    \nThese models can be simply built by using the <a class=\"reference external\" href=\"https://keras.io/guides/functional_api/\">Keras functional API</a> to stack layers.\n    \nThe following cell implements the previous system as a Keras model.\n    \nThe key functions that need to be defined are `__init__()`, which instantiates the required components, and `__call()__`, which performs forward pass through the end-to-end system.\n\n```python\n[12]:\n```\n\n```python\nclass UncodedSystemAWGN(Model): # Inherits from Keras Model\n    def __init__(self, num_bits_per_symbol, block_length):\n        \"\"\"\n        A keras model of an uncoded transmission over the AWGN channel.\n        Parameters\n        ----------\n        num_bits_per_symbol: int\n            The number of bits per constellation symbol, e.g., 4 for QAM16.\n        block_length: int\n            The number of bits per transmitted message block (will be the codeword length later).\n        Input\n        -----\n        batch_size: int\n            The batch_size of the Monte-Carlo simulation.\n        ebno_db: float\n            The `Eb/No` value (=rate-adjusted SNR) in dB.\n        Output\n        ------\n        (bits, llr):\n            Tuple:\n        bits: tf.float32\n            A tensor of shape `[batch_size, block_length] of 0s and 1s\n            containing the transmitted information bits.\n        llr: tf.float32\n            A tensor of shape `[batch_size, block_length] containing the\n            received log-likelihood-ratio (LLR) values.\n        \"\"\"\n        super().__init__() # Must call the Keras model initializer\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.block_length = block_length\n        self.constellation = sn.mapping.Constellation(\"qam\", self.num_bits_per_symbol)\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n    # @tf.function # Enable graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        # no channel coding used; we set coderate=1.0\n        no = sn.utils.ebnodb2no(ebno_db,\n                                num_bits_per_symbol=self.num_bits_per_symbol,\n                                coderate=1.0)\n        bits = self.binary_source([batch_size, self.block_length]) # Blocklength set to 1024 bits\n        x = self.mapper(bits)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper([y,no])\n        return bits, llr\n```\n\n    \nWe need first to instantiate the model.\n\n```python\n[13]:\n```\n\n```python\nmodel_uncoded_awgn = UncodedSystemAWGN(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, block_length=1024)\n```\n\n    \nSionna provides a utility to easily compute and plot the bit error rate (BER).\n\n```python\n[14]:\n```\n\n```python\nEBN0_DB_MIN = -3.0 # Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 5.0 # Maximum value of Eb/N0 [dB] for simulations\nBATCH_SIZE = 2000 # How many examples are processed by Sionna in parallel\nber_plots = sn.utils.PlotBER(\"AWGN\")\nber_plots.simulate(model_uncoded_awgn,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Uncoded\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 1.5825e-01 | 1.0000e+00 |      324099 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -2.579 | 1.4687e-01 | 1.0000e+00 |      300799 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -2.158 | 1.3528e-01 | 1.0000e+00 |      277061 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -1.737 | 1.2323e-01 | 1.0000e+00 |      252373 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -1.316 | 1.1246e-01 | 1.0000e+00 |      230320 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -0.895 | 1.0107e-01 | 1.0000e+00 |      206992 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -0.474 | 9.0021e-02 | 1.0000e+00 |      184362 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -0.053 | 8.0165e-02 | 1.0000e+00 |      164177 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    0.368 | 6.9933e-02 | 1.0000e+00 |      143222 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    0.789 | 6.0897e-02 | 1.0000e+00 |      124717 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    1.211 | 5.2020e-02 | 1.0000e+00 |      106537 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    1.632 | 4.3859e-02 | 1.0000e+00 |       89823 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    2.053 | 3.6686e-02 | 1.0000e+00 |       75132 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    2.474 | 3.0071e-02 | 1.0000e+00 |       61586 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    2.895 | 2.4304e-02 | 1.0000e+00 |       49775 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    3.316 | 1.9330e-02 | 1.0000e+00 |       39588 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    3.737 | 1.4924e-02 | 1.0000e+00 |       30565 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    4.158 | 1.1227e-02 | 1.0000e+00 |       22992 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    4.579 | 8.2632e-03 | 1.0000e+00 |       16923 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n      5.0 | 5.9722e-03 | 9.9850e-01 |       12231 |     2048000 |         1997 |        2000 |         0.0 |reached target block errors\n```\n\n\n    \nThe `sn.utils.PlotBER` object stores the results and allows to add additional simulations to the previous curves.\n    \n<em>Remark</em>: In Sionna, a block error is defined to happen if for two tensors at least one position in the last dimension differs (i.e., at least one bit wrongly received per codeword). The bit error rate the total number of erroneous positions divided by the total number of transmitted bits.\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 1: Getting Started with Sionna<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Part-1:-Getting-Started-with-Sionna\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- **Part I: Getting started with Sionna**\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n\n# Table of Content\n## Imports & Basics\n## Forward Error Correction (FEC)\n  \n  \n\n## Imports & Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Imports-&-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\n# also try %matplotlib widget\nimport matplotlib.pyplot as plt\n# for performance measurements\nimport time\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n    \nWe can now access Sionna functions within the `sn` namespace.\n    \n**Hint**: In Jupyter notebooks, you can run bash commands with `!`.\n\n```python\n[2]:\n```\n\n```python\n!nvidia-smi\n```\n\n\n```python\nTue Mar 15 14:47:45 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 30%   51C    P8    23W / 350W |     53MiB / 24265MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   33C    P8    24W / 350W |      8MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```\n## Forward Error Correction (FEC)<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Forward-Error-Correction-(FEC)\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe now add channel coding to our transceiver to make it more robust against transmission errors. For this, we will use <a class=\"reference external\" href=\"https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3214\">5G compliant low-density parity-check (LDPC) codes and Polar codes</a>. You can find more detailed information in the notebooks <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html\">Bit-Interleaved Coded Modulation (BICM)</a> and <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html\">5G Channel Coding\nand Rate-Matching: Polar vs.\u00a0LDPC Codes</a>.\n\n```python\n[15]:\n```\n\n```python\nk = 12\nn = 20\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder, hard_out=True)\n```\n\n    \nLet us encode some random input bits.\n\n```python\n[16]:\n```\n\n```python\nBATCH_SIZE = 1 # one codeword in parallel\nu = binary_source([BATCH_SIZE, k])\nprint(\"Input bits are: \\n\", u.numpy())\nc = encoder(u)\nprint(\"Encoded bits are: \\n\", c.numpy())\n```\n\n\n```python\nInput bits are:\n [[1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.]]\nEncoded bits are:\n [[1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]]\n```\n\n    \nOne of the fundamental paradigms of Sionna is batch-processing. Thus, the example above could be executed with for arbitrary batch-sizes to simulate `batch_size` codewords in parallel.\n    \nHowever, Sionna can do more - it supports <em>N</em>-dimensional input tensors and, thereby, allows the processing of multiple samples of multiple users and several antennas in a single command line. Let\u2019s say we want to encoded `batch_size` codewords of length `n` for each of the `num_users` connected to each of the `num_basestations`. This means in total we transmit `batch_size` * `n` * `num_users` * `num_basestations` bits.\n\n```python\n[17]:\n```\n\n```python\nBATCH_SIZE = 10 # samples per scenario\nnum_basestations = 4\nnum_users = 5 # users per basestation\nn = 1000 # codeword length per transmitted codeword\ncoderate = 0.5 # coderate\nk = int(coderate * n) # number of info bits per codeword\n# instantiate a new encoder for codewords of length n\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n# the decoder must be linked to the encoder (to know the exact code parameters used for encoding)\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder,\n                                    hard_out=True, # binary output or provide soft-estimates\n                                    return_infobits=True, # or also return (decoded) parity bits\n                                    num_iter=20, # number of decoding iterations\n                                    cn_type=\"boxplus-phi\") # also try \"minsum\" decoding\n# draw random bits to encode\nu = binary_source([BATCH_SIZE, num_basestations, num_users, k])\nprint(\"Shape of u: \", u.shape)\n# We can immediately encode u for all users, basetation and samples\n# This all happens with a single line of code\nc = encoder(u)\nprint(\"Shape of c: \", c.shape)\nprint(\"Total number of processed bits: \", np.prod(c.shape))\n```\n\n\n```python\nShape of u:  (10, 4, 5, 500)\nShape of c:  (10, 4, 5, 1000)\nTotal number of processed bits:  200000\n```\n\n    \nThis works for arbitrary dimensions and allows a simple extension of the designed system to multi-user or multi-antenna scenarios.\n    \nLet us now replace the LDPC code by a Polar code. The API remains similar.\n\n```python\n[18]:\n```\n\n```python\nk = 64\nn = 128\nencoder = sn.fec.polar.Polar5GEncoder(k, n)\ndecoder = sn.fec.polar.Polar5GDecoder(encoder,\n                                      dec_type=\"SCL\") # you can also use \"SCL\"\n```\n\n    \n<em>Advanced Remark:</em> The 5G Polar encoder/decoder class directly applies rate-matching and the additional CRC concatenation. This is all done internally and transparent to the user.\n    \nIn case you want to access low-level features of the Polar codes, please use `sionna.fec.polar.PolarEncoder` and the desired decoder (`sionna.fec.polar.PolarSCDecoder`, `sionna.fec.polar.PolarSCLDecoder` or `sionna.fec.polar.PolarBPDecoder`).\n    \nFurther details can be found in the tutorial notebook on <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html\">5G Channel Coding and Rate-Matching: Polar vs.\u00a0LDPC Codes</a>.\n    \n\n```python\n[19]:\n```\n\n```python\nclass CodedSystemAWGN(Model): # Inherits from Keras Model\n    def __init__(self, num_bits_per_symbol, n, coderate):\n        super().__init__() # Must call the Keras model initializer\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.n = n\n        self.k = int(n*coderate)\n        self.coderate = coderate\n        self.constellation = sn.mapping.Constellation(\"qam\", self.num_bits_per_symbol)\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(self.k, self.n)\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    #@tf.function # activate graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=self.num_bits_per_symbol, coderate=self.coderate)\n        bits = self.binary_source([batch_size, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper([y,no])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```\n```python\n[20]:\n```\n\n```python\nCODERATE = 0.5\nBATCH_SIZE = 2000\nmodel_coded_awgn = CodedSystemAWGN(num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                                   n=2048,\n                                   coderate=CODERATE)\nber_plots.simulate(model_coded_awgn,\n                   ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 15),\n                   batch_size=BATCH_SIZE,\n                   num_target_block_errors=500,\n                   legend=\"Coded\",\n                   soft_estimates=False,\n                   max_mc_iter=15,\n                   show_fig=True,\n                   forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.7896e-01 | 1.0000e+00 |      571312 |     2048000 |         2000 |        2000 |         1.8 |reached target block errors\n   -2.429 | 2.6327e-01 | 1.0000e+00 |      539174 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -1.857 | 2.4783e-01 | 1.0000e+00 |      507546 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -1.286 | 2.2687e-01 | 1.0000e+00 |      464636 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -0.714 | 2.0312e-01 | 1.0000e+00 |      415988 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -0.143 | 1.7154e-01 | 1.0000e+00 |      351316 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n    0.429 | 1.1296e-01 | 9.9050e-01 |      231337 |     2048000 |         1981 |        2000 |         1.7 |reached target block errors\n      1.0 | 2.0114e-02 | 4.7150e-01 |       41193 |     2048000 |          943 |        2000 |         1.7 |reached target block errors\n    1.571 | 1.7617e-04 | 1.1633e-02 |        5412 |    30720000 |          349 |       30000 |        25.2 |reached max iter\n    2.143 | 0.0000e+00 | 0.0000e+00 |           0 |    30720000 |            0 |       30000 |        25.3 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.1 dB.\n\n```\n\n\n    \nAs can be seen, the `BerPlot` class uses multiple stopping conditions and stops the simulation after no error occured at a specifc SNR point.\n    \n**Task**: Replace the coding scheme by a Polar encoder/decoder or a convolutional code with Viterbi decoding.\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 1: Getting Started with Sionna<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Part-1:-Getting-Started-with-Sionna\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- **Part I: Getting started with Sionna**\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n\n# Table of Content\n## Imports & Basics\n## Eager vs Graph Mode\n## Exercise\n  \n  \n\n## Imports & Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Imports-&-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\n# also try %matplotlib widget\nimport matplotlib.pyplot as plt\n# for performance measurements\nimport time\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n    \nWe can now access Sionna functions within the `sn` namespace.\n    \n**Hint**: In Jupyter notebooks, you can run bash commands with `!`.\n\n```python\n[2]:\n```\n\n```python\n!nvidia-smi\n```\n\n\n```python\nTue Mar 15 14:47:45 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 30%   51C    P8    23W / 350W |     53MiB / 24265MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   33C    P8    24W / 350W |      8MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```\n## Eager vs Graph Mode<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Eager-vs-Graph-Mode\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nSo far, we have executed the example in <em>eager</em> mode. This allows to run TensorFlow ops as if it was written NumPy and simplifies development and debugging.\n    \nHowever, to unleash Sionna\u2019s full performance, we need to activate <em>graph</em> mode which can be enabled with the function decorator <em>@tf.function()</em>.\n    \nWe refer to <a class=\"reference external\" href=\"https://www.tensorflow.org/guide/function\">TensorFlow Functions</a> for further details.\n\n```python\n[21]:\n```\n\n```python\n@tf.function() # enables graph-mode of the following function\ndef run_graph(batch_size, ebno_db):\n    # all code inside this function will be executed in graph mode, also calls of other functions\n    print(f\"Tracing run_graph for values batch_size={batch_size} and ebno_db={ebno_db}.\") # print whenever this function is traced\n    return model_coded_awgn(batch_size, ebno_db)\n```\n```python\n[22]:\n```\n\n```python\nbatch_size = 10 # try also different batch sizes\nebno_db = 1.5\n# run twice - how does the output change?\nrun_graph(batch_size, ebno_db)\n```\n\n\n```python\nTracing run_graph for values batch_size=10 and ebno_db=1.5.\n```\n```python\n[22]:\n```\n```python\n(<tf.Tensor: shape=(10, 1024), dtype=float32, numpy=\n array([[1., 1., 0., ..., 0., 1., 0.],\n        [1., 1., 1., ..., 0., 1., 1.],\n        [1., 1., 0., ..., 0., 1., 1.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 1., 0.],\n        [0., 1., 1., ..., 0., 1., 1.]], dtype=float32)>,\n <tf.Tensor: shape=(10, 1024), dtype=float32, numpy=\n array([[1., 1., 0., ..., 0., 1., 0.],\n        [1., 1., 1., ..., 0., 1., 1.],\n        [1., 1., 0., ..., 0., 1., 1.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 1., 0.],\n        [0., 1., 1., ..., 0., 1., 1.]], dtype=float32)>)\n```\n\n    \nIn graph mode, Python code (i.e., <em>non-TensorFlow code</em>) is only executed whenever the function is <em>traced</em>. This happens whenever the input signature changes.\n    \nAs can be seen above, the print statement was executed, i.e., the graph was traced again.\n    \nTo avoid this re-tracing for different inputs, we now input tensors. You can see that the function is now traced once for input tensors of same dtype.\n    \nSee <a class=\"reference external\" href=\"https://www.tensorflow.org/guide/function#rules_of_tracing\">TensorFlow Rules of Tracing</a> for details.\n    \n**Task:** change the code above such that tensors are used as input and execute the code with different input values. Understand when re-tracing happens.\n    \n<em>Remark</em>: if the input to a function is a tensor its signature must change and not <em>just</em> its value. For example the input could have a different size or datatype. For efficient code execution, we usually want to avoid re-tracing of the code if not required.\n\n```python\n[23]:\n```\n\n```python\n# You can print the cached signatures with\nprint(run_graph.pretty_printed_concrete_signatures())\n```\n\n\n```python\nrun_graph(batch_size=10, ebno_db=1.5)\n  Returns:\n    (<1>, <2>)\n      <1>: float32 Tensor, shape=(10, 1024)\n      <2>: float32 Tensor, shape=(10, 1024)\n```\n\n    \nWe now compare the throughput of the different modes.\n\n```python\n[24]:\n```\n\n```python\nrepetitions = 4 # average over multiple runs\nbatch_size = BATCH_SIZE # try also different batch sizes\nebno_db = 1.5\n# --- eager mode ---\nt_start = time.perf_counter()\nfor _ in range(repetitions):\n    bits, bits_hat = model_coded_awgn(tf.constant(batch_size, tf.int32),\n                                tf.constant(ebno_db, tf. float32))\nt_stop = time.perf_counter()\n# throughput in bit/s\nthroughput_eager = np.size(bits.numpy())*repetitions / (t_stop - t_start) / 1e6\nprint(f\"Throughput in Eager mode: {throughput_eager :.3f} Mbit/s\")\n# --- graph mode ---\n# run once to trace graph (ignored for throughput)\nrun_graph(tf.constant(batch_size, tf.int32),\n          tf.constant(ebno_db, tf. float32))\nt_start = time.perf_counter()\nfor _ in range(repetitions):\n    bits, bits_hat = run_graph(tf.constant(batch_size, tf.int32),\n                                tf.constant(ebno_db, tf. float32))\nt_stop = time.perf_counter()\n# throughput in bit/s\nthroughput_graph = np.size(bits.numpy())*repetitions / (t_stop - t_start) / 1e6\nprint(f\"Throughput in graph mode: {throughput_graph :.3f} Mbit/s\")\n\n```\n\n\n```python\nThroughput in Eager mode: 1.212 Mbit/s\nTracing run_graph for values batch_size=Tensor(&#34;batch_size:0&#34;, shape=(), dtype=int32) and ebno_db=Tensor(&#34;ebno_db:0&#34;, shape=(), dtype=float32).\nThroughput in graph mode: 8.623 Mbit/s\n```\n\n    \nLet\u2019s run the same simulation as above in graph mode.\n\n```python\n[25]:\n```\n\n```python\nber_plots.simulate(run_graph,\n                   ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 12),\n                   batch_size=BATCH_SIZE,\n                   num_target_block_errors=500,\n                   legend=\"Coded (Graph mode)\",\n                   soft_estimates=True,\n                   max_mc_iter=100,\n                   show_fig=True,\n                   forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.7922e-01 | 1.0000e+00 |      571845 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -2.273 | 2.5948e-01 | 1.0000e+00 |      531422 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -1.545 | 2.3550e-01 | 1.0000e+00 |      482301 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -0.818 | 2.0768e-01 | 1.0000e+00 |      425335 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -0.091 | 1.6918e-01 | 1.0000e+00 |      346477 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n    0.636 | 7.6115e-02 | 9.1650e-01 |      155883 |     2048000 |         1833 |        2000 |         0.2 |reached target block errors\n    1.364 | 1.7544e-03 | 7.2125e-02 |       14372 |     8192000 |          577 |        8000 |         1.0 |reached target block errors\n    2.091 | 7.8125e-08 | 2.0000e-05 |          16 |   204800000 |            4 |      200000 |        24.3 |reached max iter\n    2.818 | 0.0000e+00 | 0.0000e+00 |           0 |   204800000 |            0 |      200000 |        24.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.8 dB.\n\n```\n\n\n    \n**Task:** TensorFlow allows to <em>compile</em> graphs with <a class=\"reference external\" href=\"https://www.tensorflow.org/xla\">XLA</a>. Try to further accelerate the code with XLA (`@tf.function(jit_compile=True)`).\n    \n<em>Remark</em>: XLA is still an experimental feature and not all TensorFlow (and, thus, Sionna) functions support XLA.\n    \n**Task 2:** Check the GPU load with `!nvidia-smi`. Find the best tradeoff between batch-size and throughput for your specific GPU architecture.\n\n## Exercise<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part1.html#Exercise\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nSimulate the coded bit error rate (BER) for a Polar coded and 64-QAM modulation. Assume a codeword length of n = 200 and coderate = 0.5.\n    \n**Hint**: For Polar codes, successive cancellation list decoding (SCL) gives the best BER performance. However, successive cancellation (SC) decoding (without a list) is less complex.\n\n```python\n[26]:\n```\n\n```python\nn = 200\ncoderate = 0.5\n# *You can implement your code here*\n\n```\n\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{\"state\": {}, \"version_major\": 2, \"version_minor\": 0}\n</script>\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 2: Differentiable Communication Systems<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Part-2:-Differentiable-Communication-Systems\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- **Part II: Differentiable Communication Systems**\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Gradient Computation Through End-to-end Systems\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For saving complex Python data structures efficiently\nimport pickle\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense, Layer\n```\n\n## Gradient Computation Through End-to-end Systems<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Gradient-Computation-Through-End-to-end-Systems\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nLet\u2019s start by setting up a simple communication system that transmit bits modulated as QAM symbols over an AWGN channel.\n    \nHowever, compared to what we have previously done, we now make the constellation <em>trainable</em>. With Sionna, achieving this requires only setting a boolean parameter to `True` when instantiating the `Constellation` object.\n\n```python\n[2]:\n```\n\n```python\n# Binary source to generate uniform i.i.d. bits\nbinary_source = sn.utils.BinarySource()\n# 256-QAM constellation\nNUM_BITS_PER_SYMBOL = 6\nconstellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL, trainable=True) # The constellation is set to be trainable\n# Mapper and demapper\nmapper = sn.mapping.Mapper(constellation=constellation)\ndemapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n# AWGN channel\nawgn_channel = sn.channel.AWGN()\n```\n\n    \nAs we have already seen, we can now easily simulate forward passes through the system we have just setup\n\n```python\n[3]:\n```\n\n```python\nBATCH_SIZE = 128 # How many examples are processed by Sionna in parallel\nEBN0_DB = 17.0 # Eb/N0 in dB\nno = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                        coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\nbits = binary_source([BATCH_SIZE,\n                        1200]) # Blocklength\nx = mapper(bits)\ny = awgn_channel([x, no])\nllr = demapper([y,no])\n```\n\n    \nJust for fun, let\u2019s visualize the channel inputs and outputs\n\n```python\n[4]:\n```\n\n```python\nplt.figure(figsize=(8,8))\nplt.axes().set_aspect(1.0)\nplt.grid(True)\nplt.scatter(tf.math.real(y), tf.math.imag(y), label='Output')\nplt.scatter(tf.math.real(x), tf.math.imag(x), label='Input')\nplt.legend(fontsize=20);\n```\n\n\n    \nLet\u2019s now <em>optimize</em> the constellation through <em>stochastic gradient descent</em> (SGD). As we will see, this is made very easy by Sionna.\n    \nWe need to define a <em>loss function</em> that we will aim to minimize.\n    \nWe can see the task of the receiver as jointly solving, for each received symbol, `NUM_BITS_PER_SYMBOL` binary classification problems in order to reconstruct the transmitted bits. Therefore, a natural choice for the loss function is the <em>binary cross-entropy</em> (BCE) applied to each bit and to each received symbol.\n    \n<em>Remark:</em> The LLRs computed by the demapper are <em>logits</em> on the transmitted bits, and can therefore be used as-is to compute the BCE without any additional processing. <em>Remark 2:</em> The BCE is closely related to an achieveable information rate for bit-interleaved coded modulation systems [1,2]\n    \n[1] Georg B\u00f6cherer, \u201cPrinciples of Coded Modulation\u201d, <a class=\"reference external\" href=\"http://www.georg-boecherer.de/bocherer2018principles.pdf\">available online</a>\n    \n[2] F. Ait Aoudia and J. Hoydis, \u201cEnd-to-End Learning for OFDM: From Neural Receivers to Pilotless Communication,\u201d in IEEE Transactions on Wireless Communications, vol.\u00a021, no. 2, pp.\u00a01049-1063, Feb.\u00a02022, doi: 10.1109/TWC.2021.3101364.\n\n```python\n[5]:\n```\n\n```python\nbce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nprint(f\"BCE: {bce(bits, llr)}\")\n```\n\n\n```python\nBCE: 0.0001015052548609674\n```\n\n    \nOne iteration of SGD consists in three steps: 1. Perform a forward pass through the end-to-end system and compute the loss function 2. Compute the gradient of the loss function with respect to the trainable weights 3. Apply the gradient to the weights\n    \nTo enable gradient computation, we need to perform the forward pass (step 1) within a `GradientTape`\n\n```python\n[6]:\n```\n\n```python\nwith tf.GradientTape() as tape:\n    bits = binary_source([BATCH_SIZE,\n                            1200]) # Blocklength\n    x = mapper(bits)\n    y = awgn_channel([x, no])\n    llr = demapper([y,no])\n    loss = bce(bits, llr)\n```\n\n    \nUsing the `GradientTape`, computing the gradient is done as follows\n\n```python\n[7]:\n```\n\n```python\ngradient = tape.gradient(loss, tape.watched_variables())\n```\n\n    \n`gradient` is a list of tensor, each tensor corresponding to a trainable variable of our model.\n    \nFor this model, we only have a single trainable tensor: The constellation of shape [`2`, `2^NUM_BITS_PER_SYMBOL`], the first dimension corresponding to the real and imaginary components of the constellation points.\n    \n<em>Remark:</em> It is important to notice that the gradient computation was performed <em>through the demapper and channel</em>, which are conventional non-trainable algorithms implemented as <em>differentiable</em> Keras layers. This key feature of Sionna enables the training of end-to-end communication systems that combine both trainable and conventional and/or non-trainable signal processing algorithms.\n\n```python\n[8]:\n```\n\n```python\nfor g in gradient:\n    print(g.shape)\n```\n\n\n```python\n(2, 64)\n```\n\n    \nApplying the gradient (third step) is performed using an <em>optimizer</em>. <a class=\"reference external\" href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\">Many optimizers are available as part of TensorFlow</a>, and we use in this notebook `Adam`.\n\n```python\n[9]:\n```\n\n```python\noptimizer = tf.keras.optimizers.Adam(1e-2)\n```\n\n    \nUsing the optimizer, the gradients can be applied to the trainable weights to update them\n\n```python\n[10]:\n```\n\n```python\noptimizer.apply_gradients(zip(gradient, tape.watched_variables()));\n```\n\n    \nLet compare the constellation before and after the gradient application\n\n```python\n[11]:\n```\n\n```python\nfig = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL).show()\nfig.axes[0].scatter(tf.math.real(constellation.points), tf.math.imag(constellation.points), label='After SGD')\nfig.axes[0].legend();\n```\n\n\n    \nThe SGD step has led to slight change in the position of the constellation points. Training of a communication system using SGD consists in looping over such SGD steps until a stop criterion is met.\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 2: Differentiable Communication Systems<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Part-2:-Differentiable-Communication-Systems\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- **Part II: Differentiable Communication Systems**\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Creating Custom Layers\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For saving complex Python data structures efficiently\nimport pickle\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense, Layer\n```\n\n## Creating Custom Layers<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Creating-Custom-Layers\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nCustom trainable (or not trainable) algorithms should be implemented as <a class=\"reference external\" href=\"https://keras.io/api/layers/\">Keras layers</a>. All Sionna components, such as the mapper, demapper, channel\u2026 are implemented as Keras layers.\n    \nTo illustrate how this can be done, the next cell implements a simple neural network-based demapper which consists of three dense layers.\n\n```python\n[12]:\n```\n\n```python\nclass NeuralDemapper(Layer): # Inherits from Keras Layer\n    def __init__(self):\n        super().__init__()\n        # The three dense layers that form the custom trainable neural network-based demapper\n        self.dense_1 = Dense(64, 'relu')\n        self.dense_2 = Dense(64, 'relu')\n        self.dense_3 = Dense(NUM_BITS_PER_SYMBOL, None) # The last layer has no activation and therefore outputs logits, i.e., LLRs\n    def call(self, y):\n        # y : complex-valued with shape [batch size, block length]\n        # y is first mapped to a real-valued tensor with shape\n        #  [batch size, block length, 2]\n        # where the last dimension consists of the real and imaginary components\n        # The dense layers operate on the last dimension, and treat the inner dimensions as batch dimensions, i.e.,\n        # all the received symbols are independently processed.\n        nn_input = tf.stack([tf.math.real(y), tf.math.imag(y)], axis=-1)\n        z = self.dense_1(nn_input)\n        z = self.dense_2(z)\n        z = self.dense_3(z) # [batch size, number of symbols per block, number of bits per symbol]\n        llr = tf.reshape(z, [tf.shape(y)[0], -1]) # [batch size, number of bits per block]\n        return llr\n```\n\n    \nA custom Keras layer is used as any other Sionna layer, and therefore integration to a Sionna-based communication is straightforward.\n    \nThe following model uses the neural demapper instead of the conventional demapper. It takes at initialization a parameter that indicates if the model is intantiated to be trained or evaluated. When instantiated to be trained, the loss function is returned. Otherwise, the transmitted bits and LLRs are returned.\n\n```python\n[13]:\n```\n\n```python\nclass End2EndSystem(Model): # Inherits from Keras Model\n    def __init__(self, training):\n        super().__init__() # Must call the Keras model initializer\n        self.constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL, trainable=True) # Constellation is trainable\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = NeuralDemapper() # Intantiate the NeuralDemapper custom layer as any other\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits=True) # Loss function\n        self.training = training\n    @tf.function(jit_compile=True) # Enable graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        # no channel coding used; we set coderate=1.0\n        no = sn.utils.ebnodb2no(ebno_db,\n                                num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                                coderate=1.0)\n        bits = self.binary_source([batch_size, 1200]) # Blocklength set to 1200 bits\n        x = self.mapper(bits)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper(y)  # Call the NeuralDemapper custom layer as any other\n        if self.training:\n            loss = self.bce(bits, llr)\n            return loss\n        else:\n            return bits, llr\n```\n\n    \nWhen a model that includes a neural network is created, the neural network weights are randomly initialized typically leading to very poor performance.\n    \nTo see this, the following cell benchmarks the previously defined untrained model against a conventional baseline.\n\n```python\n[14]:\n```\n\n```python\nEBN0_DB_MIN = 10.0\nEBN0_DB_MAX = 20.0\n\n###############################\n# Baseline\n###############################\nclass Baseline(Model): # Inherits from Keras Model\n    def __init__(self):\n        super().__init__() # Must call the Keras model initializer\n        self.constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n    @tf.function # Enable graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        # no channel coding used; we set coderate=1.0\n        no = sn.utils.ebnodb2no(ebno_db,\n                                num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                                coderate=1.0)\n        bits = self.binary_source([batch_size, 1200]) # Blocklength set to 1200 bits\n        x = self.mapper(bits)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper([y,no])\n        return bits, llr\n###############################\n# Benchmarking\n###############################\nbaseline = Baseline()\nmodel = End2EndSystem(False)\nber_plots = sn.utils.PlotBER(\"Neural Demapper\")\nber_plots.simulate(baseline,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nber_plots.simulate(model,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Untrained model\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     10.0 | 2.6927e-02 | 1.0000e+00 |        4136 |      153600 |          128 |         128 |         0.7 |reached target block errors\n   10.526 | 2.1426e-02 | 1.0000e+00 |        3291 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.053 | 1.6100e-02 | 1.0000e+00 |        2473 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.579 | 1.2051e-02 | 1.0000e+00 |        1851 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.105 | 9.1927e-03 | 1.0000e+00 |        1412 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.632 | 6.5234e-03 | 1.0000e+00 |        1002 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.158 | 4.4792e-03 | 9.8438e-01 |         688 |      153600 |          126 |         128 |         0.0 |reached target block errors\n   13.684 | 2.7474e-03 | 9.6875e-01 |         422 |      153600 |          124 |         128 |         0.0 |reached target block errors\n   14.211 | 1.6146e-03 | 8.8281e-01 |         248 |      153600 |          113 |         128 |         0.0 |reached target block errors\n   14.737 | 9.9609e-04 | 7.0312e-01 |         306 |      307200 |          180 |         256 |         0.0 |reached target block errors\n   15.263 | 5.2083e-04 | 4.7266e-01 |         160 |      307200 |          121 |         256 |         0.0 |reached target block errors\n   15.789 | 3.4071e-04 | 3.3333e-01 |         157 |      460800 |          128 |         384 |         0.0 |reached target block errors\n   16.316 | 1.4193e-04 | 1.5781e-01 |         109 |      768000 |          101 |         640 |         0.0 |reached target block errors\n   16.842 | 6.0961e-05 | 7.1023e-02 |         103 |     1689600 |          100 |        1408 |         0.1 |reached target block errors\n   17.368 | 2.4113e-05 | 2.8935e-02 |         100 |     4147200 |          100 |        3456 |         0.2 |reached target block errors\n   17.895 | 7.6593e-06 | 9.1912e-03 |         100 |    13056000 |          100 |       10880 |         0.5 |reached target block errors\n   18.421 | 2.7995e-06 | 3.3594e-03 |          43 |    15360000 |           43 |       12800 |         0.6 |reached max iter\n   18.947 | 6.5104e-07 | 7.8125e-04 |          10 |    15360000 |           10 |       12800 |         0.6 |reached max iter\n   19.474 | 6.5104e-08 | 7.8125e-05 |           1 |    15360000 |            1 |       12800 |         0.5 |reached max iter\n     20.0 | 0.0000e+00 | 0.0000e+00 |           0 |    15360000 |            0 |       12800 |         0.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 20.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     10.0 | 4.7460e-01 | 1.0000e+00 |       72899 |      153600 |          128 |         128 |         1.3 |reached target block errors\n   10.526 | 4.7907e-01 | 1.0000e+00 |       73585 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.053 | 4.7525e-01 | 1.0000e+00 |       72999 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.579 | 4.7865e-01 | 1.0000e+00 |       73521 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.105 | 4.7684e-01 | 1.0000e+00 |       73242 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.632 | 4.7469e-01 | 1.0000e+00 |       72913 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.158 | 4.7614e-01 | 1.0000e+00 |       73135 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.684 | 4.7701e-01 | 1.0000e+00 |       73268 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   14.211 | 4.7544e-01 | 1.0000e+00 |       73027 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   14.737 | 4.7319e-01 | 1.0000e+00 |       72682 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   15.263 | 4.7740e-01 | 1.0000e+00 |       73329 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   15.789 | 4.7385e-01 | 1.0000e+00 |       72783 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   16.316 | 4.7344e-01 | 1.0000e+00 |       72721 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   16.842 | 4.7303e-01 | 1.0000e+00 |       72658 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   17.368 | 4.7378e-01 | 1.0000e+00 |       72773 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   17.895 | 4.7257e-01 | 1.0000e+00 |       72586 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   18.421 | 4.7377e-01 | 1.0000e+00 |       72771 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   18.947 | 4.7315e-01 | 1.0000e+00 |       72676 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   19.474 | 4.7217e-01 | 1.0000e+00 |       72525 |      153600 |          128 |         128 |         0.0 |reached target block errors\n     20.0 | 4.7120e-01 | 1.0000e+00 |       72376 |      153600 |          128 |         128 |         0.0 |reached target block errors\n```\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 2: Differentiable Communication Systems<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Part-2:-Differentiable-Communication-Systems\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- **Part II: Differentiable Communication Systems**\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Setting up Training Loops\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For saving complex Python data structures efficiently\nimport pickle\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense, Layer\n```\n\n## Setting up Training Loops<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html#Setting-up-Training-Loops\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nTraining of end-to-end communication systems consists in iterating over SGD steps.\n    \nThe next cell implements a training loop of `NUM_TRAINING_ITERATIONS` iterations. The training SNR is set to $E_b/N_0 = 15$ dB.\n    \nAt each iteration: - A forward pass through the end-to-end system is performed within a gradient tape - The gradients are computed using the gradient tape, and applied using the Adam optimizer - The estimated loss is periodically printed to follow the progress of training\n\n```python\n[15]:\n```\n\n```python\n# Number of iterations used for training\nNUM_TRAINING_ITERATIONS = 30000\n# Set a seed for reproducibility\ntf.random.set_seed(1)\n# Instantiating the end-to-end model for training\nmodel_train = End2EndSystem(training=True)\n# Adam optimizer (SGD variant)\noptimizer = tf.keras.optimizers.Adam()\n# Training loop\nfor i in range(NUM_TRAINING_ITERATIONS):\n    # Forward pass\n    with tf.GradientTape() as tape:\n        loss = model_train(BATCH_SIZE, 15.0) # The model is assumed to return the BMD rate\n    # Computing and applying gradients\n    grads = tape.gradient(loss, model_train.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model_train.trainable_weights))\n    # Print progress\n    if i % 100 == 0:\n        print(f\"{i}/{NUM_TRAINING_ITERATIONS}  Loss: {loss:.2E}\", end=\"\\r\")\n```\n\n\n```python\n29900/30000  Loss: 2.02E-03\n```\n\n    \nThe weights of the trained model are saved using <a class=\"reference external\" href=\"https://docs.python.org/3/library/pickle.html\">pickle</a>.\n\n```python\n[16]:\n```\n\n```python\n# Save the weightsin a file\nweights = model_train.get_weights()\nwith open('weights-neural-demapper', 'wb') as f:\n    pickle.dump(weights, f)\n```\n\n    \nFinally, we evaluate the trained model and benchmark it against the previously introduced baseline.\n    \nWe first instantiate the model for evaluation and load the saved weights.\n\n```python\n[17]:\n```\n\n```python\n# Instantiating the end-to-end model for evaluation\nmodel = End2EndSystem(training=False)\n# Run one inference to build the layers and loading the weights\nmodel(tf.constant(1, tf.int32), tf.constant(10.0, tf.float32))\nwith open('weights-neural-demapper', 'rb') as f:\n    weights = pickle.load(f)\n    model.set_weights(weights)\n```\n\n    \nThe trained model is then evaluated.\n\n```python\n[18]:\n```\n\n```python\n# Computing and plotting BER\nber_plots.simulate(model,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100,\n                  legend=\"Trained model\",\n                  soft_estimates=True,\n                  max_mc_iter=100,\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     10.0 | 2.6094e-02 | 1.0000e+00 |        4008 |      153600 |          128 |         128 |         0.4 |reached target block errors\n   10.526 | 2.0768e-02 | 1.0000e+00 |        3190 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.053 | 1.5729e-02 | 1.0000e+00 |        2416 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.579 | 1.1667e-02 | 1.0000e+00 |        1792 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.105 | 8.3789e-03 | 1.0000e+00 |        1287 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.632 | 6.1458e-03 | 1.0000e+00 |         944 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.158 | 3.8411e-03 | 9.7656e-01 |         590 |      153600 |          125 |         128 |         0.0 |reached target block errors\n   13.684 | 2.8971e-03 | 9.7656e-01 |         445 |      153600 |          125 |         128 |         0.0 |reached target block errors\n   14.211 | 1.6602e-03 | 8.4375e-01 |         255 |      153600 |          108 |         128 |         0.0 |reached target block errors\n   14.737 | 9.8958e-04 | 6.7578e-01 |         304 |      307200 |          173 |         256 |         0.0 |reached target block errors\n   15.263 | 5.0130e-04 | 4.7656e-01 |         154 |      307200 |          122 |         256 |         0.0 |reached target block errors\n   15.789 | 2.5228e-04 | 2.6367e-01 |         155 |      614400 |          135 |         512 |         0.0 |reached target block errors\n   16.316 | 1.4453e-04 | 1.6250e-01 |         111 |      768000 |          104 |         640 |         0.0 |reached target block errors\n   16.842 | 5.2548e-05 | 5.8594e-02 |         113 |     2150400 |          105 |        1792 |         0.1 |reached target block errors\n   17.368 | 2.7083e-05 | 3.1875e-02 |         104 |     3840000 |          102 |        3200 |         0.1 |reached target block errors\n   17.895 | 8.6520e-06 | 1.0382e-02 |         101 |    11673600 |          101 |        9728 |         0.3 |reached target block errors\n   18.421 | 2.7344e-06 | 3.2812e-03 |          42 |    15360000 |           42 |       12800 |         0.4 |reached max iter\n   18.947 | 8.4635e-07 | 1.0156e-03 |          13 |    15360000 |           13 |       12800 |         0.4 |reached max iter\n   19.474 | 1.3021e-07 | 1.5625e-04 |           2 |    15360000 |            2 |       12800 |         0.4 |reached max iter\n     20.0 | 0.0000e+00 | 0.0000e+00 |           0 |    15360000 |            0 |       12800 |         0.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 20.0 dB.\n\n```\n\n\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{\"state\": {}, \"version_major\": 2, \"version_minor\": 0}\n</script>\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 3: Advanced Link-level Simulations<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Part-3:-Advanced-Link-level-Simulations\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- **Part III: Advanced Link-level Simulations**\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## OFDM Resource Grid and Stream Management\n## Antenna Arrays\n## Channel Model\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n## OFDM Resource Grid and Stream Management<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#OFDM-Resource-Grid-and-Stream-Management\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe will setup a realistic SIMO point-to-point link between a mobile user terminal (UT) and a base station (BS). The system we will setup is shown in the figure below.\n    \n\n### Stream Management<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Stream-Management\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nFor any type of MIMO simulations, it is required to setup a `StreamManagement` object. It determines which transmitters and receivers communicate data streams with each other. In our scenario, we will configure a single UT equipped with a single antenna and a single BS equipped with multiple antennas. Whether the UT or BS is considered as a transmitter depends on the link direction, which can be either uplink or downlink. The `StreamManagement` has many properties that are used by other\ncomponents, such as precoding and equalization.\n    \nWe will configure the system here such that the number of streams per transmitter is equal to the number of UT antennas.\n\n```python\n[2]:\n```\n\n```python\n# Define the number of UT and BS antennas\nNUM_UT = 1\nNUM_BS = 1\nNUM_UT_ANT = 1\nNUM_BS_ANT = 4\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nNUM_STREAMS_PER_TX = NUM_UT_ANT\n# Create an RX-TX association matrix.\n# RX_TX_ASSOCIATION[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change.\n# For example, considering a system with 2 RX and 4 TX, the RX-TX\n# association matrix could be\n# [ [1 , 1, 0, 0],\n#   [0 , 0, 1, 1] ]\n# which indicates that the RX 0 receives from TX 0 and 1, and RX 1 receives from\n# TX 2 and 3.\n#\n# In this notebook, as we have only a single transmitter and receiver,\n# the RX-TX association matrix is simply:\nRX_TX_ASSOCIATION = np.array([[1]])\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly easy. However, it can get more involved\n# for simulations with many transmitters and receivers.\nSTREAM_MANAGEMENT = sn.mimo.StreamManagement(RX_TX_ASSOCIATION, NUM_STREAMS_PER_TX)\n```\n\n### OFDM Resource Grid<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#OFDM-Resource-Grid\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nNext, we configure an OFDM `ResourceGrid` spanning multiple OFDM symbols. The resource grid contains data symbols and pilots and is equivalent to a <em>slot</em> in 4G/5G terminology. Although it is not relevant for our simulation, we null the DC subcarrier and a few guard carriers to the left and right of the spectrum. Also a cyclic prefix is added.\n    \nDuring the creation of the `ResourceGrid`, a `PilotPattern` is automatically generated. We could have alternatively created a `PilotPattern` first and then provided it as initialization parameter. When multiple streams are considered, the corresponding pilot patterns must be orthogonal. By default, orthogonal pilots are setup when considering such systems.\n\n```python\n[3]:\n```\n\n```python\nRESOURCE_GRID = sn.ofdm.ResourceGrid( num_ofdm_symbols=14,\n                                      fft_size=76,\n                                      subcarrier_spacing=30e3,\n                                      num_tx=NUM_UT,\n                                      num_streams_per_tx=NUM_STREAMS_PER_TX,\n                                      cyclic_prefix_length=6,\n                                      pilot_pattern=\"kronecker\",\n                                      pilot_ofdm_symbol_indices=[2,11])\nRESOURCE_GRID.show();\n```\n\n```python\n[4]:\n```\n\n```python\nRESOURCE_GRID.pilot_pattern.show();\n```\n\n\n    \n**Task:** You can try different pilot patterns, FFT size, number of OFDM symbols, and visualize how it affects the resource grid.\n    \nSee the notebook <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/MIMO_OFDM_Transmissions_over_CDL.html\">MIMO_OFDM_Transmissions_over_CDL</a> for more advanced examples.\n## Antenna Arrays<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Antenna-Arrays\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe need to configure the antenna arrays used by the UT and BS. This can be ignored for simple channel models, such as `AWGN`, `RayleighBlockFading`, or `TDL` which do not account for antenna array geometries and antenna radiation patterns. However, other models, such as `CDL`, `UMi`, `UMa`, and `RMa` from the 3GPP 38.901 specification, require it.\n    \nWe will assume here that UT is equipped with one vertically single-polarized antenna and the BS antenna array is composed of dual cross-polarized antenna elements with an antenna pattern defined in the <a class=\"reference external\" href=\"https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3173\">3GPP 38.901 specification</a>. By default, the antenna elements are spaced half of a wavelength apart in both vertical and horizontal directions. You can define your own antenna geometries an\nradiation patterns if needed.\n    \nAn `AntennaArray` is always defined in the y-z plane. Its final orientation will be determined by the orientation of the UT or BS. This parameter can be configured in the `ChannelModel` that we will create later.\n\n```python\n[5]:\n```\n\n```python\nCARRIER_FREQUENCY = 2.6e9 # Carrier frequency in Hz.\n                          # This is needed here to define the antenna element spacing.\nUT_ARRAY = sn.channel.tr38901.Antenna(  polarization=\"single\",\n                                        polarization_type=\"V\",\n                                        antenna_pattern=\"38.901\",\n                                        carrier_frequency=CARRIER_FREQUENCY)\nUT_ARRAY.show();\nBS_ARRAY = sn.channel.tr38901.AntennaArray( num_rows=1,\n                                            num_cols=int(NUM_BS_ANT/2),\n                                            polarization=\"dual\",\n                                            polarization_type=\"cross\",\n                                            antenna_pattern=\"38.901\", # Try 'omni'\n                                            carrier_frequency=CARRIER_FREQUENCY)\nBS_ARRAY.show();\n```\n\n\n```python\n[6]:\n```\n\n```python\nBS_ARRAY.show_element_radiation_pattern();\n```\n\n\n\n\n    \n**Task:** You can try different antenna pattern (\u201comni\u201d), polarization, and array geometries.\n\n## Channel Model<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Channel-Model\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nSionna implements the CDL, TDL, UMi, UMa, and RMa models from <a class=\"reference external\" href=\"https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3173\">3GPP TR 38.901</a>, as well as Rayleigh block fading.\n    \nNote that: * TDL only supports SISO * CDL only supports single-user, possibly with multiple antenna * UMi, UMa, and RMa support single- and multi-user\n    \n<em>Remark:</em> The TDL and CDL models correspond to fixed power delay profiles and fixed angles.\n    \n    \nWe consider the 3GPP CDL model family in this notebook.\n\n```python\n[7]:\n```\n\n```python\nDELAY_SPREAD = 100e-9 # Nominal delay spread in [s]. Please see the CDL documentation\n                      # about how to choose this value.\nDIRECTION = \"uplink\"  # The `direction` determines if the UT or BS is transmitting.\n                      # In the `uplink`, the UT is transmitting.\nCDL_MODEL = \"C\"       # Suitable values are [\"A\", \"B\", \"C\", \"D\", \"E\"]\nSPEED = 10.0          # UT speed [m/s]. BSs are always assumed to be fixed.\n                     # The direction of travel will chosen randomly within the x-y plane.\n# Configure a channel impulse reponse (CIR) generator for the CDL model.\nCDL = sn.channel.tr38901.CDL(CDL_MODEL,\n                             DELAY_SPREAD,\n                             CARRIER_FREQUENCY,\n                             UT_ARRAY,\n                             BS_ARRAY,\n                             DIRECTION,\n                             min_speed=SPEED)\n```\n\n    \nThe instance `CDL` of the CDL model can be used to generate batches of random realizations of continuous-time channel impulse responses, consisting of complex gains `a` and delays `tau` for each path. To account for time-varying channels, a channel impulse responses is sampled at the `sampling_frequency` for `num_time_samples` samples. For more details on this, please have a look at the API documentation of the channel models.\n    \nIn order to model the channel in the frequency domain, we need `num_ofdm_symbols` samples that are taken once per `ofdm_symbol_duration`, which corresponds to the length of an OFDM symbol plus the cyclic prefix.\n\n```python\n[8]:\n```\n\n```python\nBATCH_SIZE = 128 # How many examples are processed by Sionna in parallel\na, tau = CDL(batch_size=BATCH_SIZE,\n             num_time_steps=RESOURCE_GRID.num_ofdm_symbols,\n             sampling_frequency=1/RESOURCE_GRID.ofdm_symbol_duration)\n```\nThe path gains `a` have shape\n`[batch` `size,` `num_rx,` `num_rx_ant,` `num_tx,` `num_tx_ant,` `num_paths,` `num_time_steps]`\nand the delays `tau` have shape\n`[batch_size,` `num_rx,` `num_tx,` `num_paths]`.\n\n```python\n[9]:\n```\n\n```python\nprint(\"Shape of the path gains: \", a.shape)\nprint(\"Shape of the delays:\", tau.shape)\n```\n\n\n```python\nShape of the path gains:  (128, 1, 4, 1, 1, 24, 14)\nShape of the delays: (128, 1, 1, 24)\n```\n\n    \nThe delays are assumed to be static within the time-window of interest. Only the complex path gains change over time. The following two figures depict the channel impulse response at a particular time instant and the time-evolution of the gain of one path, respectively.\n\n```python\n[10]:\n```\n\n```python\nplt.figure()\nplt.title(\"Channel impulse response realization\")\nplt.stem(tau[0,0,0,:]/1e-9, np.abs(a)[0,0,0,0,0,:,0])\nplt.xlabel(r\"$\\tau$ [ns]\")\nplt.ylabel(r\"$|a|$\")\n\nplt.figure()\nplt.title(\"Time evolution of path gain\")\nplt.plot(np.arange(RESOURCE_GRID.num_ofdm_symbols)*RESOURCE_GRID.ofdm_symbol_duration/1e-6, np.real(a)[0,0,0,0,0,0,:])\nplt.plot(np.arange(RESOURCE_GRID.num_ofdm_symbols)*RESOURCE_GRID.ofdm_symbol_duration/1e-6, np.imag(a)[0,0,0,0,0,0,:])\nplt.legend([\"Real part\", \"Imaginary part\"])\nplt.xlabel(r\"$t$ [us]\")\nplt.ylabel(r\"$a$\");\n```\n\n\n\n    \nSee the notebook <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/Realistic_Multiuser_MIMO_Simulations.html\">Realistic_Multiuser_MIMO_Simulations</a> for more advanced examples.\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 3: Advanced Link-level Simulations<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Part-3:-Advanced-Link-level-Simulations\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- **Part III: Advanced Link-level Simulations**\n- Part IV: Toward Learned Receivers\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Uplink Transmission in the Frequency Domain\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n## Uplink Transmission in the Frequency Domain<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part3.html#Uplink-Transmission-in-the-Frequency-Domain\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe are now ready to simulate a transmission.\n    \nIn the following, the channel is simulated in the frequency domain. Therefore, the channel is assumed to be constant over the duration of an OFDM symbol, which leads to not simulating the intercarrier interference (ICI) that could occur due to channel aging over the duration of OFDM symbols.\n    \nThe `OFDMChannel` layer is used to simulate the channel in the frequency domain and takes care of sampling channel impulse responses, computing the frequency responses, and applying the channel transfer function to the channel inputs (including AWGN).\n    \nNote that it is also possible to simulate the channel in time domain using the `TimeChannel` layer, which enables simulation of ICI. For more information, please have a look at the API documentation.\n\n```python\n[11]:\n```\n\n```python\nNUM_BITS_PER_SYMBOL = 2 # QPSK\nCODERATE = 0.5\n# Number of coded bits in a resource grid\nn = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL)\n# Number of information bits in a resource groud\nk = int(n*CODERATE)\n# The binary source will create batches of information bits\nbinary_source = sn.utils.BinarySource()\n# The encoder maps information bits to coded bits\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n# The mapper maps blocks of information bits to constellation symbols\nmapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n# The resource grid mapper maps symbols onto an OFDM resource grid\nrg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n# Frequency domain channel\nchannel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n# The LS channel estimator will provide channel estimates and error variances\nls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n# The LMMSE equalizer will provide soft symbols together with noise variance estimates\nlmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n# The demapper produces LLR for all coded bits\ndemapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n# The decoder provides hard-decisions on the information bits\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder, hard_out=True)\n```\n\n    \nLet\u2019s now simulate the transmission, and look at the shape of the layers outputs at each stage.\n    \nThe utility function `ebnodb2no` takes as additional input the resource grid to account for the pilots when computing the noise power spectral density ratio $N_0$ from the energy per bit to noise power spectral density ratio $E_b/N_0$ (in dB).\n\n```python\n[12]:\n```\n\n```python\nno = sn.utils.ebnodb2no(ebno_db=10.0,\n                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                        coderate=CODERATE,\n                        resource_grid=RESOURCE_GRID)\n# Transmitter\nbits = binary_source([BATCH_SIZE, NUM_UT, RESOURCE_GRID.num_streams_per_tx, k])\nprint(\"Shape of bits: \", bits.shape)\ncodewords = encoder(bits)\nprint(\"Shape of codewords: \", codewords.shape)\nx = mapper(codewords)\nprint(\"Shape of x: \", x.shape)\nx_rg = rg_mapper(x)\nprint(\"Shape of x_rg: \", x_rg.shape)\n# Channel\ny, h_freq = channel([x_rg, no])\nprint(\"Shape of y_rg: \", y.shape)\nprint(\"Shape of h_freq: \", h_freq.shape)\n# Receiver\nh_hat, err_var = ls_est ([y, no])\nprint(\"Shape of h_hat: \", h_hat.shape)\nprint(\"Shape of err_var: \", err_var.shape)\nx_hat, no_eff = lmmse_equ([y, h_hat, err_var, no])\nprint(\"Shape of x_hat: \", x_hat.shape)\nprint(\"Shape of no_eff: \", no_eff.shape)\nllr = demapper([x_hat, no_eff])\nprint(\"Shape of llr: \", llr.shape)\nbits_hat = decoder(llr)\nprint(\"Shape of bits_hat: \", bits_hat.shape)\n```\n\n\n```python\nShape of bits:  (128, 1, 1, 912)\nShape of codewords:  (128, 1, 1, 1824)\nShape of x:  (128, 1, 1, 912)\nShape of x_rg:  (128, 1, 1, 14, 76)\nShape of y_rg:  (128, 1, 4, 14, 76)\nShape of h_freq:  (128, 1, 4, 1, 1, 14, 76)\nShape of h_hat:  (128, 1, 4, 1, 1, 14, 76)\nShape of err_var:  (1, 1, 1, 1, 1, 14, 76)\nShape of x_hat:  (128, 1, 1, 912)\nShape of no_eff:  (128, 1, 1, 912)\nShape of llr:  (128, 1, 1, 1824)\nShape of bits_hat:  (128, 1, 1, 912)\n```\n\n    \nThe next cell implements the previous system as a Keras model.\n    \nMoreover, a boolean given as parameter to the initializer enables using either LS estimation or perfect CSI, as shown in the figure below.\n    \n\n```python\n[13]:\n```\n\n```python\nclass OFDMSystem(Model): # Inherits from Keras Model\n    def __init__(self, perfect_csi):\n        super().__init__() # Must call the Keras model initializer\n        self.perfect_csi = perfect_csi\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n        # The LS channel estimator will provide channel estimates and error variances\n        self.ls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n        # The LMMSE equalizer will provide soft symbols together with noise variance estimates\n        self.lmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The demapper produces LLR for all coded bits\n        self.demapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # Transmitter\n        bits = self.binary_source([batch_size, NUM_UT, RESOURCE_GRID.num_streams_per_tx, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y, h_freq = self.channel([x_rg, no])\n        # Receiver\n        if self.perfect_csi:\n            h_hat, err_var = h_freq, 0.\n        else:\n            h_hat, err_var = self.ls_est ([y, no])\n        x_hat, no_eff = self.lmmse_equ([y, h_hat, err_var, no])\n        llr = self.demapper([x_hat, no_eff])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```\n```python\n[14]:\n```\n\n```python\nEBN0_DB_MIN = -8.0 # Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 3.0 # Maximum value of Eb/N0 [dB] for simulations\nber_plots = sn.utils.PlotBER(\"OFDM over 3GPP CDL\")\nmodel_ls = OFDMSystem(False)\nber_plots.simulate(model_ls,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"LS Estimation\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nmodel_pcsi = OFDMSystem(True)\nber_plots.simulate(model_pcsi,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Perfect CSI\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nber_plots();\n```\n\n\n```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -8.0 | 4.2978e-01 | 1.0000e+00 |       50171 |      116736 |          128 |         128 |         7.0 |reached target block errors\n   -7.421 | 4.1871e-01 | 1.0000e+00 |       48878 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.842 | 4.1140e-01 | 1.0000e+00 |       48025 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.263 | 4.0080e-01 | 1.0000e+00 |       46788 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.684 | 3.8840e-01 | 1.0000e+00 |       45340 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.105 | 3.7817e-01 | 1.0000e+00 |       44146 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -4.526 | 3.6195e-01 | 1.0000e+00 |       42253 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -3.947 | 3.4381e-01 | 1.0000e+00 |       40135 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -3.368 | 3.2687e-01 | 1.0000e+00 |       38158 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.789 | 3.0678e-01 | 1.0000e+00 |       35812 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.211 | 2.8767e-01 | 1.0000e+00 |       33582 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.632 | 2.6431e-01 | 1.0000e+00 |       30855 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.053 | 2.4057e-01 | 1.0000e+00 |       28083 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.474 | 2.1041e-01 | 1.0000e+00 |       24563 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.105 | 1.5792e-01 | 9.8438e-01 |       18435 |      116736 |          126 |         128 |         0.2 |reached target block errors\n    0.684 | 3.1259e-02 | 4.3750e-01 |        7298 |      233472 |          112 |         256 |         0.3 |reached target block errors\n    1.263 | 4.5551e-04 | 1.2525e-02 |        3350 |     7354368 |          101 |        8064 |         9.9 |reached target block errors\n    1.842 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.8 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.8 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -8.0 | 2.8242e-01 | 1.0000e+00 |       32969 |      116736 |          128 |         128 |         3.4 |reached target block errors\n   -7.421 | 2.6455e-01 | 1.0000e+00 |       30883 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.842 | 2.4662e-01 | 1.0000e+00 |       28790 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.263 | 2.2697e-01 | 1.0000e+00 |       26495 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.684 | 2.0201e-01 | 1.0000e+00 |       23582 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.105 | 1.7199e-01 | 1.0000e+00 |       20078 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -4.526 | 1.0359e-01 | 9.6094e-01 |       12093 |      116736 |          123 |         128 |         0.2 |reached target block errors\n   -3.947 | 1.7351e-02 | 4.1016e-01 |        4051 |      233472 |          105 |         256 |         0.3 |reached target block errors\n   -3.368 | 1.4470e-04 | 8.4918e-03 |        1554 |    10739712 |          100 |       11776 |        14.8 |reached target block errors\n   -2.789 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        16.1 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -2.8 dB.\n\n```\n\n\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{\"state\": {}, \"version_major\": 2, \"version_minor\": 0}\n</script>\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 4: Toward Learned Receivers<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Part-4:-Toward-Learned-Receivers\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- **Part IV: Toward Learned Receivers**\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Simulation Parameters\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For saving complex Python data structures efficiently\nimport pickle\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\nfrom tensorflow.nn import relu\n```\n\n## Simulation Parameters<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Simulation-Parameters\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[2]:\n```\n\n```python\n# Bit per channel use\nNUM_BITS_PER_SYMBOL = 2 # QPSK\n# Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MIN = -3.0\n# Maximum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 5.0\n# How many examples are processed by Sionna in parallel\nBATCH_SIZE = 128\n# Coding rate\nCODERATE = 0.5\n# Define the number of UT and BS antennas\nNUM_UT = 1\nNUM_BS = 1\nNUM_UT_ANT = 1\nNUM_BS_ANT = 2\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nNUM_STREAMS_PER_TX = NUM_UT_ANT\n# Create an RX-TX association matrix.\n# RX_TX_ASSOCIATION[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change.\n# For example, considering a system with 2 RX and 4 TX, the RX-TX\n# association matrix could be\n# [ [1 , 1, 0, 0],\n#   [0 , 0, 1, 1] ]\n# which indicates that the RX 0 receives from TX 0 and 1, and RX 1 receives from\n# TX 2 and 3.\n#\n# In this notebook, as we have only a single transmitter and receiver,\n# the RX-TX association matrix is simply:\nRX_TX_ASSOCIATION = np.array([[1]])\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly easy. However, it can get more involved\n# for simulations with many transmitters and receivers.\nSTREAM_MANAGEMENT = sn.mimo.StreamManagement(RX_TX_ASSOCIATION, NUM_STREAMS_PER_TX)\nRESOURCE_GRID = sn.ofdm.ResourceGrid( num_ofdm_symbols=14,\n                                      fft_size=76,\n                                      subcarrier_spacing=30e3,\n                                      num_tx=NUM_UT,\n                                      num_streams_per_tx=NUM_STREAMS_PER_TX,\n                                      cyclic_prefix_length=6,\n                                      pilot_pattern=\"kronecker\",\n                                      pilot_ofdm_symbol_indices=[2,11])\n# Carrier frequency in Hz.\nCARRIER_FREQUENCY = 2.6e9\n# Antenna setting\nUT_ARRAY = sn.channel.tr38901.Antenna(  polarization=\"single\",\n                                        polarization_type=\"V\",\n                                        antenna_pattern=\"38.901\",\n                                        carrier_frequency=CARRIER_FREQUENCY)\nBS_ARRAY = sn.channel.tr38901.AntennaArray( num_rows=1,\n                                            num_cols=int(NUM_BS_ANT/2),\n                                            polarization=\"dual\",\n                                            polarization_type=\"cross\",\n                                            antenna_pattern=\"38.901\", # Try 'omni'\n                                            carrier_frequency=CARRIER_FREQUENCY)\n# Nominal delay spread in [s]. Please see the CDL documentation\n# about how to choose this value.\nDELAY_SPREAD = 100e-9\n# The `direction` determines if the UT or BS is transmitting.\n# In the `uplink`, the UT is transmitting.\nDIRECTION = \"uplink\"\n# Suitable values are [\"A\", \"B\", \"C\", \"D\", \"E\"]\nCDL_MODEL = \"C\"\n# UT speed [m/s]. BSs are always assumed to be fixed.\n# The direction of travel will chosen randomly within the x-y plane.\nSPEED = 10.0\n# Configure a channel impulse reponse (CIR) generator for the CDL model.\nCDL = sn.channel.tr38901.CDL(CDL_MODEL,\n                             DELAY_SPREAD,\n                             CARRIER_FREQUENCY,\n                             UT_ARRAY,\n                             BS_ARRAY,\n                             DIRECTION,\n                             min_speed=SPEED)\n```\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 4: Toward Learned Receivers<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Part-4:-Toward-Learned-Receivers\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- **Part IV: Toward Learned Receivers**\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Implemention of an Advanced Neural Receiver\n## Training the Neural Receiver\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For saving complex Python data structures efficiently\nimport pickle\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\nfrom tensorflow.nn import relu\n```\n\n## Implemention of an Advanced Neural Receiver<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Implemention-of-an-Advanced-Neural-Receiver\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe will implement a state-of-the-art neural receiver that operates over the entire resource grid of received symbols.\n    \nThe neural receiver computes LLRs on the coded bits from the received resource grid of frequency-domain baseband symbols.\n    \n    \nAs shown in the following figure, the neural receiver substitutes to the channel estimator, equalizer, and demapper.\n    \n    \nAs in [1] and [2], a neural receiver using residual convolutional layers is implemented.\n    \nConvolutional layers are leveraged to efficienly process the 2D resource grid that is fed as an input to the neural receiver.\n    \nResidual (skip) connections are used to avoid gradient vanishing [3].\n    \nFor convenience, a Keras layer that implements a <em>residual block</em> is first defined. The Keras layer that implements the neural receiver is built by stacking such blocks. The following figure shows the architecture of the neural receiver.\n    \n\n```python\n[3]:\n```\n\n```python\nclass ResidualBlock(Layer):\n    def __init__(self):\n        super().__init__()\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_1 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_1 = Conv2D(filters=128,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_2 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_2 = Conv2D(filters=128,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n    def call(self, inputs):\n        z = self._layer_norm_1(inputs)\n        z = relu(z)\n        z = self._conv_1(z)\n        z = self._layer_norm_2(z)\n        z = relu(z)\n        z = self._conv_2(z) # [batch size, num time samples, num subcarriers, num_channels]\n        # Skip connection\n        z = z + inputs\n        return z\nclass NeuralReceiver(Layer):\n    def __init__(self):\n        super().__init__()\n        # Input convolution\n        self._input_conv = Conv2D(filters=128,\n                                  kernel_size=[3,3],\n                                  padding='same',\n                                  activation=None)\n        # Residual blocks\n        self._res_block_1 = ResidualBlock()\n        self._res_block_2 = ResidualBlock()\n        self._res_block_3 = ResidualBlock()\n        self._res_block_4 = ResidualBlock()\n        # Output conv\n        self._output_conv = Conv2D(filters=NUM_BITS_PER_SYMBOL,\n                                   kernel_size=[3,3],\n                                   padding='same',\n                                   activation=None)\n    def call(self, inputs):\n        y, no = inputs\n        # Assuming a single receiver, remove the num_rx dimension\n        y = tf.squeeze(y, axis=1)\n        # Feeding the noise power in log10 scale helps with the performance\n        no = sn.utils.log10(no)\n        # Stacking the real and imaginary components of the different antennas along the 'channel' dimension\n        y = tf.transpose(y, [0, 2, 3, 1]) # Putting antenna dimension last\n        no = sn.utils.insert_dims(no, 3, 1)\n        no = tf.tile(no, [1, y.shape[1], y.shape[2], 1])\n        # z : [batch size, num ofdm symbols, num subcarriers, 2*num rx antenna + 1]\n        z = tf.concat([tf.math.real(y),\n                       tf.math.imag(y),\n                       no], axis=-1)\n        # Input conv\n        z = self._input_conv(z)\n        # Residual blocks\n        z = self._res_block_1(z)\n        z = self._res_block_2(z)\n        z = self._res_block_3(z)\n        z = self._res_block_4(z)\n        # Output conv\n        z = self._output_conv(z)\n        # Reshape the input to fit what the resource grid demapper is expected\n        z = sn.utils.insert_dims(z, 2, 1)\n        return z\n```\n\n    \nThe task of the receiver is to jointly solve, for each resource element, `NUM_BITS_PER_SYMBOL` binary classification problems in order to reconstruct the transmitted bits. Therefore, a natural choice for the loss function is the <em>binary cross-entropy</em> (BCE) applied to each bit and to each received symbol.\n    \n<em>Remark:</em> The LLRs computed by the demapper are <em>logits</em> on the transmitted bits, and can therefore be used as-is to compute the BCE without any additional processing. <em>Remark 2:</em> The BCE is closely related to an achieveable information rate for bit-interleaved coded modulation systems [4,5]\n    \nThe next cell defines an end-to-end communication system using the neural receiver layer.\n    \nAt initialization, the paramater `training` indicates if the system is instantiated to be trained (`True`) or evaluated (`False`).\n    \nIf the system is instantiated to be trained, the outer encoder and decoder are not used as they are not required for training. Moreover, the estimated BCE is returned. This significantly reduces the computational complexity of training.\n    \nIf the system is instantiated to be evaluated, the outer encoder and decoder are used, and the transmited information and corresponding LLRs are returned.\n\n```python\n[4]:\n```\n\n```python\nclass OFDMSystemNeuralReceiver(Model): # Inherits from Keras Model\n    def __init__(self, training):\n        super().__init__() # Must call the Keras model initializer\n        self.training = training\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        self.n = n\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=False)\n        # Neural receiver\n        self.neural_receiver = NeuralReceiver()\n        # Used to extract data-carrying resource elements\n        self.rg_demapper = sn.ofdm.ResourceGridDemapper(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n        # Loss function\n        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits=True) # Loss function\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # The neural receiver is expected no to have shape [batch_size].\n        if len(no.shape) == 0:\n            no = tf.fill([batch_size], no)\n        # Transmitter\n        # Outer coding is only performed if not training\n        if self.training:\n            codewords = self.binary_source([batch_size, NUM_UT, NUM_UT_ANT, self.n])\n        else:\n            bits = self.binary_source([batch_size, NUM_UT, NUM_UT_ANT, self.k])\n            codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y = self.channel([x_rg, no])\n        # Receiver\n        llr = self.neural_receiver([y, no])\n        llr = self.rg_demapper(llr) # Extract data-carrying resource elements. The other LLrs are discarded\n        llr = tf.reshape(llr, [batch_size, NUM_UT, NUM_UT_ANT, self.n]) # Reshape the LLRs to fit what the outer decoder is expected\n        if self.training:\n            loss = self.bce(codewords, llr)\n            return loss\n        else:\n            bits_hat = self.decoder(llr)\n            return bits, bits_hat\n```\n\n## Training the Neural Receiver<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Training-the-Neural-Receiver\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThe next cell implements a training loop of `NUM_TRAINING_ITERATIONS` iterations.\n    \nAt each iteration: - A batch of SNRs $E_b/N_0$ is sampled - A forward pass through the end-to-end system is performed within a gradient tape - The gradients are computed using the gradient tape, and applied using the Adam optimizer - A progress bar is periodically updated to follow the progress of training\n    \nAfter training, the weights of the models are saved in a file using <a class=\"reference external\" href=\"https://docs.python.org/3/library/pickle.html\">pickle</a>.\n\n```python\n[ ]:\n```\n\n```python\n# Set a seed for reproducibility\ntf.random.set_seed(1)\n# Number of iterations used for training\nNUM_TRAINING_ITERATIONS = 100000\n# Instantiating the end-to-end model for training\nmodel = OFDMSystemNeuralReceiver(training=True)\n# Adam optimizer (SGD variant)\noptimizer = tf.keras.optimizers.Adam()\n# Training loop\nfor i in range(NUM_TRAINING_ITERATIONS):\n    # Sample a batch of SNRs.\n    ebno_db = tf.random.uniform(shape=[BATCH_SIZE], minval=EBN0_DB_MIN, maxval=EBN0_DB_MAX)\n    # Forward pass\n    with tf.GradientTape() as tape:\n        loss = model(BATCH_SIZE, ebno_db)\n    # Computing and applying gradients\n    weights = model.trainable_weights\n    grads = tape.gradient(loss, weights)\n    optimizer.apply_gradients(zip(grads, weights))\n    # Print progress\n    if i % 100 == 0:\n        print(f\"{i}/{NUM_TRAINING_ITERATIONS}  Loss: {loss:.2E}\", end=\"\\r\")\n# Save the weightsin a file\nweights = model.get_weights()\nwith open('weights-ofdm-neuralrx', 'wb') as f:\n    pickle.dump(weights, f)\n```\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Part 4: Toward Learned Receivers<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Part-4:-Toward-Learned-Receivers\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n    \nThe tutorial is structured in four notebooks:\n \n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- **Part IV: Toward Learned Receivers**\n\n    \nThe <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna\">official documentation</a> provides key material on how to use Sionna and how its components are implemented.\n \n# Table of Content\n## Imports\n## Benchmarking the Neural Receiver\n## Conclusion\n  \n  \n\n## Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For saving complex Python data structures efficiently\nimport pickle\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\nfrom tensorflow.nn import relu\n```\n\n## Benchmarking the Neural Receiver<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Benchmarking-the-Neural-Receiver\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe evaluate the trained model and benchmark it against the previously introduced baselines.\n    \nWe first define and evaluate the baselines.\n\n```python\n[5]:\n```\n\n```python\nclass OFDMSystem(Model): # Inherits from Keras Model\n    def __init__(self, perfect_csi):\n        super().__init__() # Must call the Keras model initializer\n        self.perfect_csi = perfect_csi\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n        # The LS channel estimator will provide channel estimates and error variances\n        self.ls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n        # The LMMSE equalizer will provide soft symbols together with noise variance estimates\n        self.lmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The demapper produces LLR for all coded bits\n        self.demapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # Transmitter\n        bits = self.binary_source([batch_size, NUM_UT, RESOURCE_GRID.num_streams_per_tx, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y, h_freq = self.channel([x_rg, no])\n        # Receiver\n        if self.perfect_csi:\n            h_hat, err_var = h_freq, 0.\n        else:\n            h_hat, err_var = self.ls_est ([y, no])\n        x_hat, no_eff = self.lmmse_equ([y, h_hat, err_var, no])\n        llr = self.demapper([x_hat, no_eff])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```\n```python\n[6]:\n```\n\n```python\nber_plots = sn.utils.PlotBER(\"Advanced neural receiver\")\nbaseline_ls = OFDMSystem(False)\nber_plots.simulate(baseline_ls,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline: LS Estimation\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nbaseline_pcsi = OFDMSystem(True)\nber_plots.simulate(baseline_pcsi,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline: Perfect CSI\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\n```\n\n\n```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 3.6894e-01 | 1.0000e+00 |       43069 |      116736 |          128 |         128 |         7.7 |reached target block errors\n   -2.579 | 3.5806e-01 | 1.0000e+00 |       41799 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 3.4527e-01 | 1.0000e+00 |       40305 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 3.3213e-01 | 1.0000e+00 |       38771 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 3.2260e-01 | 1.0000e+00 |       37659 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.895 | 3.0787e-01 | 1.0000e+00 |       35940 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.474 | 2.9344e-01 | 1.0000e+00 |       34255 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.053 | 2.7841e-01 | 1.0000e+00 |       32501 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.368 | 2.6109e-01 | 1.0000e+00 |       30479 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.789 | 2.4077e-01 | 1.0000e+00 |       28107 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    1.211 | 2.2460e-01 | 1.0000e+00 |       26219 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    1.632 | 1.9116e-01 | 1.0000e+00 |       22315 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    2.053 | 1.5909e-01 | 1.0000e+00 |       18572 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    2.474 | 9.3930e-02 | 8.6719e-01 |       10965 |      116736 |          111 |         128 |         0.2 |reached target block errors\n    2.895 | 2.1987e-02 | 3.8281e-01 |        7700 |      350208 |          147 |         384 |         0.5 |reached target block errors\n    3.316 | 1.5316e-03 | 4.2352e-02 |        3397 |     2217984 |          103 |        2432 |         2.9 |reached target block errors\n    3.737 | 1.1607e-04 | 1.6406e-03 |        1355 |    11673600 |           21 |       12800 |        15.5 |reached max iter\n    4.158 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.2 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.1695e-01 | 1.0000e+00 |       25326 |      116736 |          128 |         128 |         3.4 |reached target block errors\n   -2.579 | 1.9826e-01 | 1.0000e+00 |       23144 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 1.7926e-01 | 1.0000e+00 |       20926 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 1.3810e-01 | 1.0000e+00 |       16121 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 7.1966e-02 | 8.7500e-01 |        8401 |      116736 |          112 |         128 |         0.2 |reached target block errors\n   -0.895 | 1.6267e-02 | 3.6719e-01 |        5697 |      350208 |          141 |         384 |         0.5 |reached target block errors\n   -0.474 | 6.2963e-04 | 2.8181e-02 |        2058 |     3268608 |          101 |        3584 |         4.3 |reached target block errors\n   -0.053 | 4.5916e-05 | 8.5938e-04 |         536 |    11673600 |           11 |       12800 |        15.4 |reached max iter\n    0.368 | 2.9126e-05 | 1.5625e-04 |         340 |    11673600 |            2 |       12800 |        15.4 |reached max iter\n    0.789 | 1.5676e-05 | 7.8125e-05 |         183 |    11673600 |            1 |       12800 |        15.4 |reached max iter\n    1.211 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.2 dB.\n\n```\n\n    \nWe then instantiate and evaluate the end-to-end system equipped with the neural receiver.\n\n```python\n[7]:\n```\n\n```python\n# Instantiating the end-to-end model for evaluation\nmodel_neuralrx = OFDMSystemNeuralReceiver(training=False)\n# Run one inference to build the layers and loading the weights\nmodel_neuralrx(tf.constant(1, tf.int32), tf.constant(10.0, tf.float32))\nwith open('weights-ofdm-neuralrx', 'rb') as f:\n    weights = pickle.load(f)\n    model_neuralrx.set_weights(weights)\n```\n```python\n[8]:\n```\n\n```python\n# Computing and plotting BER\nber_plots.simulate(model_neuralrx,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100,\n                  legend=\"Neural Receiver\",\n                  soft_estimates=True,\n                  max_mc_iter=100,\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.2083e-01 | 1.0000e+00 |       25779 |      116736 |          128 |         128 |         0.3 |reached target block errors\n   -2.579 | 2.0480e-01 | 1.0000e+00 |       23907 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 1.8219e-01 | 1.0000e+00 |       21268 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 1.4852e-01 | 1.0000e+00 |       17338 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 9.0503e-02 | 9.4531e-01 |       10565 |      116736 |          121 |         128 |         0.2 |reached target block errors\n   -0.895 | 2.2251e-02 | 4.4922e-01 |        5195 |      233472 |          115 |         256 |         0.3 |reached target block errors\n   -0.474 | 1.7106e-03 | 6.4303e-02 |        2596 |     1517568 |          107 |        1664 |         2.2 |reached target block errors\n   -0.053 | 1.4828e-04 | 3.2812e-03 |        1731 |    11673600 |           42 |       12800 |        16.6 |reached max iter\n    0.368 | 6.3305e-05 | 6.2500e-04 |         739 |    11673600 |            8 |       12800 |        16.5 |reached max iter\n    0.789 | 8.6520e-06 | 1.5625e-04 |         101 |    11673600 |            2 |       12800 |        16.5 |reached max iter\n    1.211 | 4.2832e-07 | 7.8125e-05 |           5 |    11673600 |            1 |       12800 |        16.6 |reached max iter\n    1.632 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        16.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.6 dB.\n\n```\n\n## Conclusion<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#Conclusion\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe hope you are excited about Sionna - there is much more to be discovered:\n \n- TensorBoard debugging available\n- Scaling to multi-GPU simulation is simple\n- See the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/tutorials.html\">available tutorials</a> for more examples\n\n    \nAnd if something is still missing - the project is open-source: you can modify, add, and extend any component at any time.\n    \nTo get started you can use the `pip` installer:\n\n```python\n[ ]:\n```\n\n```python\n!pip install sionna\n```\n\n## References<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part4.html#References\" title=\"Permalink to this headline\">\uf0c1</a>\n    \n[1] <a class=\"reference external\" href=\"https://ieeexplore.ieee.org/abstract/document/9345504\">M. Honkala, D. Korpi and J. M. J. Huttunen, \u201cDeepRx: Fully Convolutional Deep Learning Receiver,\u201d in IEEE Transactions on Wireless Communications, vol.\u00a020, no. 6, pp.\u00a03925-3940, June 2021, doi: 10.1109/TWC.2021.3054520</a>.\n    \n[2] <a class=\"reference external\" href=\"https://ieeexplore.ieee.org/abstract/document/9508784\">F. Ait Aoudia and J. Hoydis, \u201cEnd-to-end Learning for OFDM: From Neural Receivers to Pilotless Communication,\u201d in IEEE Transactions on Wireless Communications, doi: 10.1109/TWC.2021.3101364</a>.\n    \n[3] <a class=\"reference external\" href=\"https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html\">Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, \u201cDeep Residual Learning for Image Recognition\u201d, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.\u00a0770-778</a>\n<script type=\"application/vnd.jupyter.widget-state+json\">\n{\"state\": {}, \"version_major\": 2, \"version_minor\": 0}\n</script>\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Pulse-shaping Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#Pulse-shaping-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this tutorial notebook, you will learn about various components of Sionna\u2019s signal module, such as pulse-shaping filters, windowing functions, as well as layers for up- and down-sampling.\n    \nBelow is a schematic diagram of the used components and how they connect. For simplicity, we have not added any channel between the pulse-shaping filter and the matched filter.\n    \n    \nYou will learn how to:\n \n- Use filters for pulse-shaping and matched filtering\n- Visualize impulse and magnitude responses\n- Compute the empirical power spectral density (PSD) and adjacent channel leakage power ratio (ACLR)\n- Apply the Upsampling and Downsampling layers\n- Add windowing to filters for improved spectral characteristics\n# Table of Content\n## GPU Configuration and Imports\n## Pulse-shaping of a sequence of QAM symbols\n## Recovering the QAM symbols through matched filtering and downsampling\n## Investigating the ACLR\n  \n  \n\n## GPU Configuration and Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#GPU-Configuration-and-Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n```python\n[2]:\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.utils import QAMSource\nfrom sionna.signal import Upsampling, Downsampling, RootRaisedCosineFilter, empirical_psd, empirical_aclr\n```\n\n## Pulse-shaping of a sequence of QAM symbols<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#Pulse-shaping-of-a-sequence-of-QAM-symbols\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWe start by creating a root-raised-cosine filter with a roll-off factor of 0.22, spanning 32 symbols, with an oversampling factor of four.\n\n```python\n[3]:\n```\n\n```python\nbeta = 0.22 # Roll-off factor\nspan_in_symbols = 32 # Filter span in symbold\nsamples_per_symbol = 4 # Number of samples per symbol, i.e., the oversampling factor\nrrcf = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta)\n```\n\n    \nAll filters have a function to visualize their impulse response $h(t)$ and magnitude response $H(f)$, i.e., the absolute value of the Fourier transform of $h(t)$. The symbol duration is denoted $T$ and the bandwidth $W$. The <em>normalized time</em> and <em>normalized frequency</em> are then defined as $t/T$ and $f/W$, respectively.\n\n```python\n[4]:\n```\n\n```python\nrrcf.show(\"impulse\")\nrrcf.show(\"magnitude\", \"db\") # Logarithmic scale\nrrcf.show(\"magnitude\", \"lin\") # Linear scale\n```\n\n\n\n\n    \nIn Sionna, filters have always an odd number of samples. This is despite the fact that the product <em>span_in_symbols</em> $\\times$ <em>samples_per_symbol</em> can be even. Let us verify the length property of our root-raised-cosine filter:\n\n```python\n[5]:\n```\n\n```python\nprint(\"Filter length:\", rrcf.length)\n```\n\n\n```python\nFilter length: 129\n```\n\n    \nNext, we will use this filter to pulse shape a sequence of QAM symbols. This requires upsampling of the sequence to the desired sampling rate. The sampling rate is defined as the number of samples per symbol $k$, and upsampling simply means that $k-1$ zeros are inserted after every QAM symbol.\n\n```python\n[6]:\n```\n\n```python\n# Configure QAM source\nnum_bits_per_symbol = 4 # The modulation order of the QAM constellation, i.e., 16QAM\nqam = QAMSource(num_bits_per_symbol) # Layer to generate batches of QAM symbols\n# Generate batch of QAM symbol sequences\nbatch_size = 128\nnum_symbols = 1000\nx = qam([batch_size, num_symbols])\nprint(\"Shape of x\", x.shape)\n# Create instance of the Upsampling layer\nus = Upsampling(samples_per_symbol)\n# Upsample the QAM symbol sequence\nx_us = us(x)\nprint(\"Shape of x_us\", x_us.shape)\n# Inspect the first few elements of one row of x_us\nplt.stem(np.abs(x_us)[0,:20]);\nplt.xlabel(r\"Sample index $i$\")\nplt.ylabel(r\"|$x_{us}[i]$|\");\n```\n\n\n```python\nShape of x (128, 1000)\nShape of x_us (128, 4000)\n```\n\n\n    \nAfter upsampling, we can apply the filter:\n\n```python\n[7]:\n```\n\n```python\n# Filter the upsampled sequence\nx_rrcf = rrcf(x_us)\n```\n\n## Recovering the QAM symbols through matched filtering and downsampling<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#Recovering-the-QAM-symbols-through-matched-filtering-and-downsampling\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn order to recover the QAM symbols from this waveform, we need to apply a matched filter, i.e., the same filter in our case, and downsample the result, starting from the correct index. This index can be obtained as follows. The transmit filter has its peak value after $(L-1)/2$ samples, where $L$ is the filter length. If we apply the same filter for reception, the peak will be delayed by a total of $L-1$ samples. The code in the following cell creates a Downsampling layer that\nallows us to recover the transmitted symbol sequence.\n\n```python\n[8]:\n```\n\n```python\n# Apply the matched filter\nx_mf = rrcf(x_rrcf)\n# Instantiate a downsampling layer\nds = Downsampling(samples_per_symbol, rrcf.length-1, num_symbols)\n# Recover the transmitted symbol sequence\nx_hat = ds(x_mf)\n# Visualize the different signals\nplt.figure(figsize=(12, 8))\nplt.plot(np.real(x_us[0]), \"x\")\nplt.plot(np.real(x_rrcf[0, rrcf.length//2:]))\nplt.plot(np.real(x_mf[0, rrcf.length-1:]));\nplt.xlim(0,100)\nplt.legend([r\"Oversampled sequence of QAM symbols $x_{us}$\",\n            r\"Transmitted sequence after pulse shaping $x_{rrcf}$\",\n            r\"Received sequence after matched filtering $x_{mf}$\"]);\n```\n\n\n    \nWe can see nicely from the above figure that the signal after matched filtering overlaps almost perfectly with the oversampled sequence of QAM symbols at the symbol times. As further verification, we will next show a scatter plot of the transmitted and recovered symbols and compute the mean-squared error (MSE) between them. As one can see, the MSE is not zero, which is due to truncation of the filter to finite length. The MSE can be reduced by making the filter longer or by increasing the\nroll-off factor.\n    \nGive it a try and change <em>span_in_symbols</em> above to a larger number, e.g., 100. This will reduce the MSE by around 26dB.\n\n```python\n[9]:\n```\n\n```python\nplt.figure()\nplt.scatter(np.real(x_hat), np.imag(x_hat));\nplt.scatter(np.real(x), np.imag(x));\nplt.legend([\"Transmitted\", \"Received\"]);\nplt.title(\"Scatter plot of the transmitted and received QAM symbols\")\nprint(\"MSE between x and x_hat (dB)\", 10*np.log10(np.var(x-x_hat)))\n```\n\n\n```python\nMSE between x and x_hat (dB) -53.42741012573242\n```\n\n## Investigating the ACLR<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#Investigating-the-ACLR\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nAn important metric of waveforms is the so-called adjacent channel leakage power ratio, or short ACLR. It is defined as the ratio of the out-of-band power and the in-band power. One can get a first idea of the ACLR by looking at the power spectral density (PSD) of a transmitted signal.\n\n```python\n[10]:\n```\n\n```python\nempirical_psd(x_rrcf, oversampling=samples_per_symbol, ylim=[-100, 3]);\n```\n\n\n    \nThe in-band is defined by the interval from [-0.5, 0.5] in normalized frequency. Due to the non-zero roll-of factor, a significant amount of energy is located out of this band. The resulting ACLR can be computed with the following convenience function:\n\n```python\n[11]:\n```\n\n```python\naclr_db = 10*np.log10(empirical_aclr(x_rrcf, oversampling=samples_per_symbol))\nprint(\"Empirical ACLR (db):\", aclr_db)\n```\n\n\n```python\nEmpirical ACLR (db): -13.801279067993164\n```\n\n    \nWe can now verify that this empirical ACLR is well aligned with the theoretical ACLR that can be computed based on the magnitude response of the pulse-shaping filter. Every filter provides this value as the property <em>Filter.aclr</em>.\n\n```python\n[12]:\n```\n\n```python\nprint(\"Filter ACLR (dB)\", 10*np.log10(rrcf.aclr))\n```\n\n\n```python\nFilter ACLR (dB) -13.805673122406006\n```\n\n    \nWe can improve the ACLR by decreasing the roll-off factor $\\beta$ from 0.22 to 0.1:\n\n```python\n[13]:\n```\n\n```python\nprint(\"Filter ACLR (dB)\", 10*np.log10(RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, 0.1).aclr))\n```\n\n\n```python\nFilter ACLR (dB) -17.342106103897095\n```\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
[{"role": "user", "content": "I'm building a dataset for model training focused on the \"sionna\" Python package, based on the given following markdown context. Cover the markdown context as much as you can.Your role is to generate clear, concise instructions (as user questions) that will guide the model in mastering Sionna coding.Start each instruction with \"INSTRUCTION:\" and tailor it to fit the provided context, ensuring to cover as much of the context's information as possible for comprehensive learning.\n\n<CONTEXT>\n# Pulse-shaping Basics<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#Pulse-shaping-Basics\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nIn this tutorial notebook, you will learn about various components of Sionna\u2019s signal module, such as pulse-shaping filters, windowing functions, as well as layers for up- and down-sampling.\n    \nBelow is a schematic diagram of the used components and how they connect. For simplicity, we have not added any channel between the pulse-shaping filter and the matched filter.\n    \n    \nYou will learn how to:\n \n- Use filters for pulse-shaping and matched filtering\n- Visualize impulse and magnitude responses\n- Compute the empirical power spectral density (PSD) and adjacent channel leakage power ratio (ACLR)\n- Apply the Upsampling and Downsampling layers\n- Add windowing to filters for improved spectral characteristics\n# Table of Content\n## GPU Configuration and Imports\n## Windowing\n  \n  \n\n## GPU Configuration and Imports<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#GPU-Configuration-and-Imports\" title=\"Permalink to this headline\">\uf0c1</a>\n\n```python\n[1]:\n```\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n```python\n[2]:\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.utils import QAMSource\nfrom sionna.signal import Upsampling, Downsampling, RootRaisedCosineFilter, empirical_psd, empirical_aclr\n```\n\n## Windowing<a class=\"headerlink\" href=\"https://nvlabs.github.io/sionna/examples/Pulse_shaping_basics.html#Windowing\" title=\"Permalink to this headline\">\uf0c1</a>\n    \nWindowing can be used to improve the spectral properties of a truncated filter. For a filter of length $L$, a window is a real-valued vector of the same length that is multiplied element-wise with the filter coefficients. This is equivalent to a convolution of the filter and the window in the frequency domain.\n    \nLet us now create a slightly shorter root-raised-cosine filter and compare its properties with and without windowing. One can see that windowing leads to a much reduced out-of-band attenuation. However, the passband of the filter is also broadened which leads to an even slightly increased ACLR.\n\n```python\n[14]:\n```\n\n```python\nspan_in_symbols = 8 # Filter span in symbols\nsamples_per_symbol = 8 # Number of samples per symbol, i.e., the oversampling factor\nrrcf_short = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta)\nrrcf_short_blackman = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=\"blackman\")\nrrcf_short_blackman.window.show(samples_per_symbol)\nrrcf_short_blackman.window.show(samples_per_symbol, domain=\"frequency\", scale=\"db\")\nrrcf_short.show()\nplt.title(\"Impulse response without windowing\")\nrrcf_short_blackman.show()\nplt.title(\"Impulse response with windowing\")\nrrcf_short.show(\"magnitude\", \"db\")\nplt.title(\"Magnitude response without windowing\")\nrrcf_short_blackman.show(\"magnitude\", \"db\")\nplt.title(\"Magnitude response with windowing\")\nprint(\"ACLR (db) without window\", 10*np.log10(rrcf_short.aclr))\nprint(\"ACLR (db) with window\", 10*np.log10(rrcf_short_blackman.aclr))\n```\n\n\n```python\nACLR (db) without window -13.982985019683838\nACLR (db) with window -12.624131441116333\n```\n\n\n\n\n\n\n\n</CONTEXT>\n\nThese instructions are crucial for teaching the model to effectively understand and apply Sionna's code and APIs, tailored to real-world programming scenarios."}]
