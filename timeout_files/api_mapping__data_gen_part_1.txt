# Mapping

## Constellations
### class: sionna.mapping.Constellation(constellation_type, num_bits_per_symbol, initial_value=None, normalize=True, center=False, trainable=False, dtype=tf.complex64, **kwargs)
### sionna.mapping.qam(num_bits_per_symbol, normalize=True)
### sionna.mapping.pam(num_bits_per_symbol, normalize=True)
### sionna.mapping.pam_gray(b)
## Mapper
### class: sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)
## Demapping
### class: sionna.mapping.Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)
### class: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
### class: sionna.mapping.SymbolDemapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)
### class: sionna.mapping.SymbolDemapperWithPrior(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
## Utility Functions

# Mapping

This module contains classes and functions related to mapping of bits to constellation symbols and demapping of soft-symbols to log-likelihood ratios (LLRs). The key components are the Constellation, Mapper, and Demapper. A Constellation can be made trainable to enable learning of geometric shaping.

## Constellations
### class: sionna.mapping.Constellation(constellation_type, num_bits_per_symbol, initial_value=None, normalize=True, center=False, trainable=False, dtype=tf.complex64, **kwargs)
Constellation that can be used by a (de)mapper.
This class defines a constellation, i.e., a complex-valued vector of constellation points. A constellation can be trainable. The binary representation of the index of an element of this vector corresponds to the bit label of the constellation point. This implicit bit labeling is used by the Mapper and Demapper classes.
Parameters
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, the constellation points are randomly initialized if no initial_value is provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16.
initial_value (
[2^\text{num_bits_per_symbol}]
, NumPy array or Tensor) – Initial values of the constellation points. If normalize or center are True, the initial constellation might be changed.
normalize (bool) – If True, the constellation is normalized to have unit power. Defaults to True.
center (bool) – If True, the constellation is ensured to have zero mean. Defaults to False.
trainable (bool) – If True, the constellation points are trainable variables. Defaults to False.
dtype ([tf.complex64, tf.complex128], tf.DType) – The dtype of the constellation.
Output
[2^\text{num_bits_per_symbol}]
, dtype – The constellation.
Note
One can create a trainable PAM/QAM constellation. This is equivalent to creating a custom trainable constellation which is initialized with PAM/QAM constellation points.
property
center
Indicates if the constellation is centered.
create_or_check_constellation(num_bits_per_symbol=None, constellation=None, dtype=tf.complex64)[source]
Static method for conviently creating a constellation object or checking that an existing one is consistent with requested settings.
If constellation is None, then this method creates a Constellation object of type constellation_type and with num_bits_per_symbol bits per symbol. Otherwise, this method checks that constellation is consistent with constellation_type and num_bits_per_symbol. If it is, constellation is returned. Otherwise, an assertion is raised.
Input
constellation_type (One of [“qam”, “pam”, “custom”], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
Output
Constellation – A constellation object.
property
normalize
Indicates if the constellation is normalized or not.
property
num_bits_per_symbol
The number of bits per constellation symbol.
property
points
The (possibly) centered and normalized constellation points.
show(labels=True, figsize=(7, 7))[source]
Generate a scatter-plot of the constellation.
Input
labels (bool) – If True, the bit labels will be drawn next to each constellation point. Defaults to True.
figsize (Two-element Tuple, float) – Width and height in inches. Defaults to (7,7).
Output
matplotlib.figure.Figure – A handle to a matplot figure object.
### sionna.mapping.qam(num_bits_per_symbol, normalize=True)
Generates a QAM constellation.
This function generates a complex-valued vector, where each element is a constellation point of an M-ary QAM constellation. The bit label of the n th point is given by the length-num_bits_per_symbol binary represenation of n.
Input
num_bits_per_symbol (int) – The number of bits per constellation point. Must be a multiple of two, e.g., 2, 4, 6, 8, etc.
normalize (bool) – If True, the constellation is normalized to have unit power. Defaults to True.
Output
[2^\text{num_bits_per_symbol}]
, np.complex64 – The QAM constellation.
Note
The bit label of the nth constellation point is given by the binary representation of its position within the array and can be obtained through np.binary_repr(n, num_bits_per_symbol).
The normalization factor of a QAM constellation is given in closed-form as:
\sqrt{\frac{1}{2^{n-2}}\sum_{i=1}^{2^{n-1}}(2i-1)^2}
where
n= \text{num_bits_per_symbol}/2
is the number of bits per dimension.
This algorithm is a recursive implementation of the expressions found in Section 5.1 of [3GPPTS38211]. It is used in the 5G standard.
### sionna.mapping.pam(num_bits_per_symbol, normalize=True)
Generates a PAM constellation.
This function generates a real-valued vector, where each element is a constellation point of an M-ary PAM constellation. The bit label of the n th point is given by the length-num_bits_per_symbol binary represenation of n.
Input
num_bits_per_symbol (int) – The number of bits per constellation point. Must be positive.
normalize (bool) – If True, the constellation is normalized to have unit power. Defaults to True.
Output
[2^{\text{num_bits_per_symbol}}]
, np.float32 – The PAM constellation.
Note
The bit label of the nth constellation point is given by the binary representation of its position within the array and can be obtained through np.binary_repr(n, num_bits_per_symbol).
The normalization factor of a PAM constellation is given in closed-form as:
\sqrt{\frac{1}{2^{n-1}}\sum_{i=1}^{2^{n-1}}(2i-1)^2}
where
n= \text{num_bits_per_symbol}
is the number of bits per symbol.
This algorithm is a recursive implementation of the expressions found in Section 5.1 of [3GPPTS38211]. It is used in the 5G standard.
### sionna.mapping.pam_gray(b)
Maps a vector of bits to a PAM constellation points with Gray labeling.
This recursive function maps a binary vector to Gray-labelled PAM constellation points. It can be used to generated QAM constellations. The constellation is not normalized.
Input
b ([n], NumPy array) – Tensor with with binary entries.
Output
signed int – The PAM constellation point taking values in
\{\pm 1,\pm 3,\dots,\pm (2^n-1)\}
.
Note
This algorithm is a recursive implementation of the expressions found in Section 5.1 of [3GPPTS38211]. It is used in the 5G standard.
## Mapper
### class: sionna.mapping.Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, return_indices=False, dtype=tf.complex64, **kwargs)
Maps binary tensors to points of a constellation.
This class defines a layer that maps a tensor of binary values to a tensor of points from a provided constellation.
Parameters
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
return_indices (bool) – If enabled, symbol indices are additionally returned. Defaults to False.
dtype (One of [tf.complex64, tf.complex128], tf.DType) – The output dtype. Defaults to tf.complex64.
Input
[…, n], tf.float or tf.int – Tensor with with binary entries.
Output
[…,n/Constellation.num_bits_per_symbol], tf.complex – The mapped constellation symbols.
[…,n/Constellation.num_bits_per_symbol], tf.int32 – The symbol indices corresponding to the constellation symbols. Only returned if return_indices is set to True.
Note
The last input dimension must be an integer multiple of the number of bits per constellation symbol.
property
constellation
The Constellation used by the Mapper.
## Demapping
### class: sionna.mapping.Demapper(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)
Computes log-likelihood ratios (LLRs) or hard-decisions on bits for a tensor of received symbols. If the flag with_prior is set, prior knowledge on the bits is assumed to be available.
This class defines a layer implementing different demapping functions. All demapping functions are fully differentiable when soft-decisions are computed.
Parameters
demapping_method (One of ["app", "maxlog"], str) – The demapping method used.
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
hard_out (bool) – If True, the demapper provides hard-decided bits instead of soft-values. Defaults to False.
with_prior (bool) – If True, it is assumed that prior knowledge on the bits is available. This prior information is given as LLRs as an additional input to the layer. Defaults to False.
dtype (One of [tf.complex64, tf.complex128] tf.DType (dtype)) – The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).
Input
(y,no) or (y, prior, no) – Tuple:
y ([…,n], tf.complex) – The received symbols.
prior ([num_bits_per_symbol] or […,num_bits_per_symbol], tf.float) – Prior for every bit as LLRs. It can be provided either as a tensor of shape [num_bits_per_symbol] for the entire input batch, or as a tensor that is “broadcastable” to […, n, num_bits_per_symbol]. Only required if the with_prior flag is set.
no (Scalar or […,n], tf.float) – The noise variance estimate. It can be provided either as scalar for the entire input batch or as a tensor that is “broadcastable” to y.
Output
[…,n*num_bits_per_symbol], tf.float – LLRs or hard-decisions for every bit.
Note
With the “app” demapping method, the LLR for the
i\text{th}
bit is computed according to
LLR(i) = \ln\left(\frac{\Pr\left(b_i=1\lvert y,\mathbf{p}\right)}{\Pr\left(b_i=0\lvert y,\mathbf{p}\right)}\right) =\ln\left(\frac{
        \sum_{c\in\mathcal{C}_{i,1}} \Pr\left(c\lvert\mathbf{p}\right)
        \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }{
        \sum_{c\in\mathcal{C}_{i,0}} \Pr\left(c\lvert\mathbf{p}\right)
        \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }\right)
where
\mathcal{C}_{i,1}
and
\mathcal{C}_{i,0}
are the sets of constellation points for which the
i\text{th}
bit is equal to 1 and 0, respectively.
\mathbf{p} = \left[p_0,\dots,p_{K-1}\right]
is the vector of LLRs that serves as prior knowledge on the
K
bits that are mapped to a constellation point and is set to
\mathbf{0}
if no prior knowledge is assumed to be available, and
\Pr(c\lvert\mathbf{p})
is the prior probability on the constellation symbol
c
:
\Pr\left(c\lvert\mathbf{p}\right) = \prod_{k=0}^{K-1} \text{sigmoid}\left(p_k \ell(c)_k\right)
where
\ell(c)_k
is the
k^{th}
bit label of
c
, where 0 is replaced by -1. The definition of the LLR has been chosen such that it is equivalent with that of logits. This is different from many textbooks in communications, where the LLR is defined as
LLR(i) = \ln\left(\frac{\Pr\left(b_i=0\lvert y\right)}{\Pr\left(b_i=1\lvert y\right)}\right)
.
With the “maxlog” demapping method, LLRs for the
i\text{th}
bit are approximated like
\begin{split}\begin{align}
    LLR(i) &\approx\ln\left(\frac{
        \max_{c\in\mathcal{C}_{i,1}} \Pr\left(c\lvert\mathbf{p}\right)
            \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }{
        \max_{c\in\mathcal{C}_{i,0}} \Pr\left(c\lvert\mathbf{p}\right)
            \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }\right)\\
        &= \max_{c\in\mathcal{C}_{i,0}}
            \left(\ln\left(\Pr\left(c\lvert\mathbf{p}\right)\right)-\frac{|y-c|^2}{N_o}\right) -
         \max_{c\in\mathcal{C}_{i,1}}\left( \ln\left(\Pr\left(c\lvert\mathbf{p}\right)\right) - \frac{|y-c|^2}{N_o}\right)
        .
\end{align}\end{split}
−
### class: sionna.mapping.DemapperWithPrior(demapping_method, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
Computes log-likelihood ratios (LLRs) or hard-decisions on bits for a tensor of received symbols, assuming that prior knowledge on the bits is available.
This class defines a layer implementing different demapping functions. All demapping functions are fully differentiable when soft-decisions are computed.
This class is deprecated as the functionality has been integrated into Demapper.
Parameters
demapping_method (One of ["app", "maxlog"], str) – The demapping method used.
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
hard_out (bool) – If True, the demapper provides hard-decided bits instead of soft-values. Defaults to False.
dtype (One of [tf.complex64, tf.complex128] tf.DType (dtype)) – The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).
Input
(y, prior, no) – Tuple:
y ([…,n], tf.complex) – The received symbols.
prior ([num_bits_per_symbol] or […,num_bits_per_symbol], tf.float) – Prior for every bit as LLRs. It can be provided either as a tensor of shape [num_bits_per_symbol] for the entire input batch, or as a tensor that is “broadcastable” to […, n, num_bits_per_symbol].
no (Scalar or […,n], tf.float) – The noise variance estimate. It can be provided either as scalar for the entire input batch or as a tensor that is “broadcastable” to y.
Output
[…,n*num_bits_per_symbol], tf.float – LLRs or hard-decisions for every bit.
Note
With the “app” demapping method, the LLR for the
i\text{th}
bit is computed according to
LLR(i) = \ln\left(\frac{\Pr\left(b_i=1\lvert y,\mathbf{p}\right)}{\Pr\left(b_i=0\lvert y,\mathbf{p}\right)}\right) =\ln\left(\frac{
        \sum_{c\in\mathcal{C}_{i,1}} \Pr\left(c\lvert\mathbf{p}\right)
        \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }{
        \sum_{c\in\mathcal{C}_{i,0}} \Pr\left(c\lvert\mathbf{p}\right)
        \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }\right)
where
\mathcal{C}_{i,1}
and
\mathcal{C}_{i,0}
are the sets of constellation points for which the
i\text{th}
bit is equal to 1 and 0, respectively.
\mathbf{p} = \left[p_0,\dots,p_{K-1}\right]
is the vector of LLRs that serves as prior knowledge on the
K
bits that are mapped to a constellation point, and
\Pr(c\lvert\mathbf{p})
is the prior probability on the constellation symbol
c
:
\Pr\left(c\lvert\mathbf{p}\right) = \prod_{k=0}^{K-1} \text{sigmoid}\left(p_k \ell(c)_k\right)
where
\ell(c)_k
is the
k^{th}
bit label of
c
, where 0 is replaced by -1. The definition of the LLR has been chosen such that it is equivalent with that of logits. This is different from many textbooks in communications, where the LLR is defined as
LLR(i) = \ln\left(\frac{\Pr\left(b_i=0\lvert y\right)}{\Pr\left(b_i=1\lvert y\right)}\right)
.
With the “maxlog” demapping method, LLRs for the
i
th
bit are approximated like
\begin{split}\begin{align}
    LLR(i) &\approx\ln\left(\frac{
        \max_{c\in\mathcal{C}_{i,1}} \Pr\left(c\lvert\mathbf{p}\right)
            \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }{
        \max_{c\in\mathcal{C}_{i,0}} \Pr\left(c\lvert\mathbf{p}\right)
            \exp\left(-\frac{1}{N_o}\left|y-c\right|^2\right)
        }\right)\\
        &= \max_{c\in\mathcal{C}_{i,0}}
            \left(\ln\left(\Pr\left(c\lvert\mathbf{p}\right)\right)-\frac{|y-c|^2}{N_o}\right) -
         \max_{c\in\mathcal{C}_{i,1}}\left( \ln\left(\Pr\left(c\lvert\mathbf{p}\right)\right) - \frac{|y-c|^2}{N_o}\right)
        .
\end{align}\end{split}
−
### class: sionna.mapping.SymbolDemapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)
Computes normalized log-probabilities (logits) or hard-decisions on symbols for a tensor of received symbols. If the with_prior flag is set, prior knowldge on the transmitted constellation points is assumed to be available. The demapping function is fully differentiable when soft-values are computed.
Parameters
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
hard_out (bool) – If True, the demapper provides hard-decided symbols instead of soft-values. Defaults to False.
with_prior (bool) – If True, it is assumed that prior knowledge on the constellation points is available. This prior information is given as log-probabilities (logits) as an additional input to the layer. Defaults to False.
dtype (One of [tf.complex64, tf.complex128] tf.DType (dtype)) – The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).
Input
(y, no) or (y, prior, no) – Tuple:
y ([…,n], tf.complex) – The received symbols.
prior ([num_points] or […,num_points], tf.float) – Prior for every symbol as log-probabilities (logits). It can be provided either as a tensor of shape [num_points] for the entire input batch, or as a tensor that is “broadcastable” to […, n, num_points]. Only required if the with_prior flag is set.
no (Scalar or […,n], tf.float) – The noise variance estimate. It can be provided either as scalar for the entire input batch or as a tensor that is “broadcastable” to y.
Output
[…,n, num_points] or […,n], tf.float – A tensor of shape […,n, num_points] of logits for every constellation point if hard_out is set to False. Otherwise, a tensor of shape […,n] of hard-decisions on the symbols.
Note
The normalized log-probability for the constellation point
c
is computed according to
\ln\left(\Pr\left(c \lvert y,\mathbf{p}\right)\right) = \ln\left( \frac{\exp\left(-\frac{|y-c|^2}{N_0} + p_c \right)}{\sum_{c'\in\mathcal{C}} \exp\left(-\frac{|y-c'|^2}{N_0} + p_{c'} \right)} \right)
−
where
\mathcal{C}
is the set of constellation points used for modulation, and
\mathbf{p} = \left\{p_c \lvert c \in \mathcal{C}\right\}
the prior information on constellation points given as log-probabilities and which is set to
0
if no prior information on the constellation points is assumed to be available.
### class: sionna.mapping.SymbolDemapperWithPrior(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
Computes normalized log-probabilities (logits) or hard-decisions on symbols for a tensor of received symbols, assuming that prior knowledge on the constellation points is available. The demapping function is fully differentiable when soft-values are computed.
This class is deprecated as the functionality has been integrated into SymbolDemapper.
Parameters
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
hard_out (bool) – If True, the demapper provides hard-decided symbols instead of soft-values. Defaults to False.
dtype (One of [tf.complex64, tf.complex128] tf.DType (dtype)) – The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).
Input
(y, prior, no) – Tuple:
y ([…,n], tf.complex) – The received symbols.
prior ([num_points] or […,num_points], tf.float) – Prior for every symbol as log-probabilities (logits). It can be provided either as a tensor of shape [num_points] for the entire input batch, or as a tensor that is “broadcastable” to […, n, num_points].
no (Scalar or […,n], tf.float) – The noise variance estimate. It can be provided either as scalar for the entire input batch or as a tensor that is “broadcastable” to y.
Output
[…,n, num_points] or […,n], tf.float – A tensor of shape […,n, num_points] of logits for every constellation point if hard_out is set to False. Otherwise, a tensor of shape […,n] of hard-decisions on the symbols.
Note
The normalized log-probability for the constellation point
c
is computed according to
\ln\left(\Pr\left(c \lvert y,\mathbf{p}\right)\right) = \ln\left( \frac{\exp\left(-\frac{|y-c|^2}{N_0} + p_c \right)}{\sum_{c'\in\mathcal{C}} \exp\left(-\frac{|y-c'|^2}{N_0} + p_{c'} \right)} \right)
−
where
\mathcal{C}
is the set of constellation points used for modulation, and
\mathbf{p} = \left\{p_c \lvert c \in \mathcal{C}\right\}
the prior information on constellation points given as log-probabilities.
## Utility Functions
