# Multiple-Input Multiple-Output (MIMO)

## Detection
### class: sionna.mimo.MaximumLikelihoodDetectorWithPrior(output, demapping_method, num_streams, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
### class: sionna.mimo.MMSEPICDetector(output, demapping_method='maxlog', num_iter=1, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
## Utility Functions
### class: sionna.mimo.List2LLR
### class: sionna.mimo.List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, **kwargs)

# Multiple-Input Multiple-Output (MIMO)

This module provides layers and functions to support simulation of multicell MIMO transmissions.

### class: sionna.mimo.MaximumLikelihoodDetectorWithPrior(output, demapping_method, num_streams, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
MIMO maximum-likelihood (ML) detector, assuming prior knowledge on the bits or constellation points is available.
This class is deprecated as the functionality has been integrated into MaximumLikelihoodDetector.
This layer implements MIMO maximum-likelihood (ML) detection assuming the following channel model:
\mathbf{y} = \mathbf{H}\mathbf{x} + \mathbf{n}
where
\mathbf{y}\in\mathbb{C}^M
is the received signal vector,
\mathbf{x}\in\mathcal{C}^K
is the vector of transmitted symbols which are uniformly and independently drawn from the constellation
C
,
\mathbf{H}\in\mathbb{C}^{M\times K}
is the known channel matrix, and
\mathbf{n}\in\mathbb{C}^M
is a complex Gaussian noise vector. It is assumed that
\mathbb{E}\left[\mathbf{n}\right]=\mathbf{0}
and
\mathbb{E}\left[\mathbf{n}\mathbf{n}^{\mathsf{H}}\right]=\mathbf{S}
, where
\mathbf{S}
has full rank. It is assumed that prior information of the transmitted signal
\mathbf{x}
is available, provided either as LLRs on the bits modulated onto
\mathbf{x}
or as logits on the individual constellation points forming
\mathbf{x}
.
Prior to demapping, the received signal is whitened:
\begin{split}\tilde{\mathbf{y}} &= \mathbf{S}^{-\frac{1}{2}}\mathbf{y}\\
&=  \mathbf{S}^{-\frac{1}{2}}\mathbf{H}\mathbf{x} + \mathbf{S}^{-\frac{1}{2}}\mathbf{n}\\
&= \tilde{\mathbf{H}}\mathbf{x} + \tilde{\mathbf{n}}\end{split}
The layer can compute ML detection of symbols or bits with either soft- or hard-decisions. Note that decisions are computed symbol-/bit-wise and not jointly for the entire vector
\textbf{x}
(or the underlying vector of bits).
ML detection of bits:
Soft-decisions on bits are called log-likelihood ratios (LLR). With the “app” demapping method, the LLR for the
i\text{th}
bit of the
k\text{th}
user is then computed according to
\begin{split}\begin{align}
    LLR(k,i)&= \ln\left(\frac{\Pr\left(b_{k,i}=1\lvert \mathbf{y},\mathbf{H}\right)}{\Pr\left(b_{k,i}=0\lvert \mathbf{y},\mathbf{H}\right)}\right)\\
            &=\ln\left(\frac{
            \sum_{\mathbf{x}\in\mathcal{C}_{k,i,1}} \exp\left(
                -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2
                \right) \Pr\left( \mathbf{x} \right)
            }{
            \sum_{\mathbf{x}\in\mathcal{C}_{k,i,0}} \exp\left(
                -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2
                \right) \Pr\left( \mathbf{x} \right)
            }\right)
\end{align}\end{split}
where
\mathcal{C}_{k,i,1}
and
\mathcal{C}_{k,i,0}
are the sets of vectors of constellation points for which the
i\text{th}
bit of the
k\text{th}
user is equal to 1 and 0, respectively.
\Pr\left( \mathbf{x} \right)
is the prior distribution of the vector of constellation points
\mathbf{x}
. Assuming that the constellation points and bit levels are independent, it is computed from the prior of the bits according to
\Pr\left( \mathbf{x} \right) = \prod_{k=1}^K \prod_{i=1}^{I} \sigma \left( LLR_p(k,i) \right)
where
LLR_p(k,i)
is the prior knowledge of the
i\text{th}
bit of the
k\text{th}
user given as an LLR, and
\sigma\left(\cdot\right)
is the sigmoid function. The definition of the LLR has been chosen such that it is equivalent with that of logit. This is different from many textbooks in communications, where the LLR is defined as
LLR(k,i) = \ln\left(\frac{\Pr\left(b_{k,i}=0\lvert \mathbf{y},\mathbf{H}\right)}{\Pr\left(b_{k,i}=1\lvert \mathbf{y},\mathbf{H}\right)}\right)
.
With the “maxlog” demapping method, the LLR for the
i\text{th}
bit of the
k\text{th}
user is approximated like
\begin{split}\begin{align}
    LLR(k,i) \approx&\ln\left(\frac{
        \max_{\mathbf{x}\in\mathcal{C}_{k,i,1}} \left( \exp\left(
            -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2
            \right) \Pr\left( \mathbf{x} \right) \right)
        }{
        \max_{\mathbf{x}\in\mathcal{C}_{k,i,0}} \left( \exp\left(
            -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2
            \right) \Pr\left( \mathbf{x} \right) \right)
        }\right)\\
        = &\min_{\mathbf{x}\in\mathcal{C}_{k,i,0}} \left( \left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2 - \ln \left(\Pr\left( \mathbf{x} \right) \right) \right) -
            \min_{\mathbf{x}\in\mathcal{C}_{k,i,1}} \left( \left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2 - \ln \left( \Pr\left( \mathbf{x} \right) \right) \right).
    \end{align}\end{split}
ML detection of symbols:
Soft-decisions on symbols are called logits (i.e., unnormalized log-probability).
With the “app” demapping method, the logit for the constellation point
c \in \mathcal{C}
of the
k\text{th}
user is computed according to
\begin{align}
    \text{logit}(k,c) &= \ln\left(\sum_{\mathbf{x} : x_k = c} \exp\left(
                -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2
                \right)\Pr\left( \mathbf{x} \right)\right).
\end{align}
With the “maxlog” demapping method, the logit for the constellation point
c \in \mathcal{C}
of the
k\text{th}
user is approximated like
\text{logit}(k,c) \approx \max_{\mathbf{x} : x_k = c} \left(
        -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2 + \ln \left( \Pr\left( \mathbf{x} \right) \right)
        \right).
When hard decisions are requested, this layer returns for the
k
th stream
\hat{c}_k = \underset{c \in \mathcal{C}}{\text{argmax}} \left( \sum_{\mathbf{x} : x_k = c} \exp\left(
                -\left\lVert\tilde{\mathbf{y}}-\tilde{\mathbf{H}}\mathbf{x}\right\rVert^2
                \right)\Pr\left( \mathbf{x} \right) \right)where
C
is the set of constellation points.
Parameters
output (One of ["bit", "symbol"], str) – The type of output, either LLRs on bits or logits on constellation symbols.
demapping_method (One of ["app", "maxlog"], str) – The demapping method used.
num_streams (tf.int) – Number of transmitted streams
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
hard_out (bool) – If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.
dtype (One of [tf.complex64, tf.complex128] tf.DType (dtype)) – The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).
Input
(y, h, prior, s) – Tuple:
y ([…,M], tf.complex) – 1+D tensor containing the received signals.
h ([…,M,num_streams], tf.complex) – 2+D tensor containing the channel matrices.
prior ([…,num_streams,num_bits_per_symbol] or […,num_streams,num_points], tf.float) – Prior of the transmitted signals. If output equals “bit”, then LLRs of the transmitted bits are expected. If output equals “symbol”, then logits of the transmitted constellation points are expected.
s ([…,M,M], tf.complex) – 2+D tensor containing the noise covariance matrices.
Output
One of
[…, num_streams, num_bits_per_symbol], tf.float – LLRs or hard-decisions for every bit of every stream, if output equals “bit”.
[…, num_streams, num_points], tf.float or […, num_streams], tf.int – Logits or hard-decisions for constellation symbols for every stream, if output equals “symbol”. Hard-decisions correspond to the symbol indices.
Note
If you want to use this layer in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat.
### class: sionna.mimo.MMSEPICDetector(output, demapping_method='maxlog', num_iter=1, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)
Minimum mean square error (MMSE) with parallel interference cancellation (PIC) detector
This layer implements the MMSE PIC detector, as proposed in [CST2011]. For num_iter>1, this implementation performs MMSE PIC self-iterations. MMSE PIC self-iterations can be understood as a concatenation of MMSE PIC detectors from [CST2011], which forward intrinsic LLRs to the next self-iteration.
Compared to [CST2011], this implementation also accepts priors on the constellation symbols as an alternative to priors on the bits.
This layer assumes the following channel model:
\mathbf{y} = \mathbf{H}\mathbf{x} + \mathbf{n}
where
\mathbf{y}\in\mathbb{C}^M
is the received signal vector,
\mathbf{x}\in\mathcal{C}^S
is the vector of transmitted symbols which are uniformly and independently drawn from the constellation
C
,
\mathbf{H}\in\mathbb{C}^{M\times S}
is the known channel matrix, and
\mathbf{n}\in\mathbb{C}^M
is a complex Gaussian noise vector. It is assumed that
\mathbb{E}\left[\mathbf{n}\right]=\mathbf{0}
and
\mathbb{E}\left[\mathbf{n}\mathbf{n}^{\mathsf{H}}\right]=\mathbf{S}
, where
S
has full rank.
The algorithm starts by computing the soft symbols
\bar{x}_s=\mathbb{E}\left[ x_s \right]
and variances
v_s=\mathbb{E}\left[ |e_s|^2\right]
from the priors, where
e_s = x_s - \bar{x}_s
, for all
s=1,\dots,S
.
Next, for each stream, the interference caused by all other streams is cancelled from the observation
\mathbf{y}
, leading to
\hat{\mathbf{y}}_s = \mathbf{y} - \sum_{j\neq s} \mathbf{h}_j x_j = \mathbf{h}_s x_s + \tilde{\mathbf{n}}_s,\quad s=1,\dots,S
where
\tilde{\mathbf{n}}_s=\sum_{j\neq s} \mathbf{h}_j e_j + \mathbf{n}
.
Then, a linear MMSE filter
\mathbf{w}_s
is computed to reduce the resdiual noise for each observation
\hat{\mathbf{y}}_s
, which is given as
\mathbf{w}_s = \mathbf{h}_s^{\mathsf{H}}\left( \mathbf{H} \mathbf{D}_s\mathbf{H}^{\mathsf{H}} +\mathbf{S} \right)^{-1}
where
\mathbf{D}_s \in \mathbb{C}^{S\times S}
is diagonal with entries
\begin{split}\left[\mathbf{D}_s\right]_{i,i} = \begin{cases}
                                    v_i & i\neq s \\
                                    1 & i=s.
                                  \end{cases}\end{split}
.
The filtered observations
\tilde{z}_s = \mathbf{w}_s^{\mathsf{H}} \hat{\mathbf{y}}_s = \tilde{\mu}_s x_s + \mathbf{w}_s^{\mathsf{H}}\tilde{\mathbf{n}}_s
where
\tilde{\mu}_s=\mathbf{w}_s^{\mathsf{H}} \mathbf{h}_s
, are then demapped to either symbol logits or LLRs, assuming that the remaining noise is Gaussian with variance
\nu_s^2 = \mathop{\text{Var}}\left[\tilde{z}_s\right] = \mathbf{w}_s^{\mathsf{H}} \left(\sum_{j\neq s} \mathbf{h}_j \mathbf{h}_j^{\mathsf{H}} v_j +\mathbf{S} \right)\mathbf{w}_s.
.
The resulting soft-symbols can then be used for the next self-iteration of the algorithm.
Note that this algorithm can be substantially simplified as described in [CST2011] to avoid the computation of different matrix inverses for each stream. This is the version which is implemented.
Parameters
output (One of ["bit", "symbol"], str) – The type of output, either LLRs on bits or logits on constellation symbols.
demapping_method (One of ["app", "maxlog"], str) – The demapping method used. Defaults to “maxlog”.
num_iter (int) – Number of MMSE PIC iterations. Defaults to 1.
constellation_type (One of ["qam", "pam", "custom"], str) – For “custom”, an instance of Constellation must be provided.
num_bits_per_symbol (int) – The number of bits per constellation symbol, e.g., 4 for QAM16. Only required for constellation_type in [“qam”, “pam”].
constellation (Constellation) – An instance of Constellation or None. In the latter case, constellation_type and num_bits_per_symbol must be provided.
hard_out (bool) – If True, the detector computes hard-decided bit values or constellation point indices instead of soft-values. Defaults to False.
dtype (One of [tf.complex64, tf.complex128] tf.DType (dtype)) – The dtype of y. Defaults to tf.complex64. The output dtype is the corresponding real dtype (tf.float32 or tf.float64).
Input
(y, h, prior, s) – Tuple:
y ([…,M], tf.complex) – 1+D tensor containing the received signals
h ([…,M,S], tf.complex) – 2+D tensor containing the channel matrices
prior ([…,S,num_bits_per_symbol] or […,S,num_points], tf.float) – Prior of the transmitted signals. If output equals “bit”, then LLRs of the transmitted bits are expected. If output equals “symbol”, then logits of the transmitted constellation points are expected.
s ([…,M,M], tf.complex) – 2+D tensor containing the noise covariance matrices
Output
One of
[…,S,num_bits_per_symbol], tf.float – LLRs or hard-decisions for every bit of every stream, if output equals “bit”
[…,S,2**num_bits_per_symbol], tf.float or […,S], tf.int – Logits or hard-decisions for constellation symbols for every stream, if output equals “symbol”
Note
For numerical stability, we do not recommend to use this function in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True). However, it is possible to do so by setting sionna.Config.xla_compat=true. See xla_compat.
## Utility Functions
### class: sionna.mimo.List2LLR
Abstract class defining a callable to compute LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.
The following channel model is assumed
\bar{\mathbf{y}} = \mathbf{R}\bar{\mathbf{x}} + \bar{\mathbf{n}}
where
\bar{\mathbf{y}}\in\mathbb{C}^S
are the channel outputs,
\mathbf{R}\in\mathbb{C}^{S\times S}
is an upper-triangular matrix,
\bar{\mathbf{x}}\in\mathbb{C}^S
is the transmitted vector whose entries are uniformly and independently drawn from the constellation
C
, and
\bar{\mathbf{n}}\in\mathbb{C}^S
is white noise with
\mathbb{E}\left[\bar{\mathbf{n}}\right]=\mathbf{0}
and
\mathbb{E}\left[\bar{\mathbf{n}}\bar{\mathbf{n}}^{\mathsf{H}}\right]=\mathbf{I}
.
It is assumed that a MIMO detector such as KBestDetector produces
K
candidate solutions
\bar{\mathbf{x}}_k\in\mathcal{C}^S
and their associated distance metrics
d_k=\lVert \bar{\mathbf{y}} - \mathbf{R}\bar{\mathbf{x}}_k \rVert^2
for
k=1,\dots,K
. This layer can also be used with the real-valued representation of the channel.
Input
(y, r, dists, path_inds, path_syms) – Tuple:
y ([…,M], tf.complex or tf.float) – Channel outputs of the whitened channel
r ([…,num_streams, num_streams], same dtype as y) – Upper triangular channel matrix of the whitened channel
dists ([…,num_paths], tf.float) – Distance metric for each path (or candidate)
path_inds ([…,num_paths,num_streams], tf.int32) – Symbol indices for every stream of every path (or candidate)
path_syms ([…,num_path,num_streams], same dtype as y) – Constellation symbol for every stream of every path (or candidate)
Output
llr ([…num_streams,num_bits_per_symbol], tf.float) – LLRs for all bits of every stream
Note
An implementation of this class does not need to make use of all of the provided inputs which enable various different implementations.
### class: sionna.mimo.List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, **kwargs)
Computes LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.
The following channel model is assumed:
\bar{\mathbf{y}} = \mathbf{R}\bar{\mathbf{x}} + \bar{\mathbf{n}}
¯
where
\bar{\mathbf{y}}\in\mathbb{C}^S
are the channel outputs,
\mathbf{R}\in\mathbb{C}^{S\times S}
is an upper-triangular matrix,
\bar{\mathbf{x}}\in\mathbb{C}^S
is the transmitted vector whose entries are uniformly and independently drawn from the constellation
\mathcal{C}
, and
\bar{\mathbf{n}}\in\mathbb{C}^S
is white noise with
\mathbb{E}\left[\bar{\mathbf{n}}\right]=\mathbf{0}
and
\mathbb{E}\left[\bar{\mathbf{n}}\bar{\mathbf{n}}^{\mathsf{H}}\right]=\mathbf{I}
.
It is assumed that a MIMO detector such as KBestDetector produces
K
candidate solutions
\bar{\mathbf{x}}_k\in\mathcal{C}^S
and their associated distance metrics
d_k=\lVert \bar{\mathbf{y}} - \mathbf{R}\bar{\mathbf{x}}_k \rVert^2
for
k=1,\dots,K
. This layer can also be used with the real-valued representation of the channel.
The LLR for the
i\text{th}
bit of the
k\text{th}
stream is computed as
\begin{split}\begin{align}
    LLR(k,i) &= \log\left(\frac{\Pr(b_{k,i}=1|\bar{\mathbf{y}},\mathbf{R})}{\Pr(b_{k,i}=0|\bar{\mathbf{y}},\mathbf{R})}\right)\\
        &\approx \min_{j \in  \mathcal{C}_{k,i,0}}d_j - \min_{j \in  \mathcal{C}_{k,i,1}}d_j
\end{align}\end{split}
where
\mathcal{C}_{k,i,1}
and
\mathcal{C}_{k,i,0}
are the set of indices in the list of candidates for which the
i\text{th}
bit of the
k\text{th}
stream is equal to 1 and 0, respectively. The LLRs are clipped to
\pm LLR_\text{clip}
which can be configured through the parameter llr_clip_val.
If
\mathcal{C}_{k,i,0}
is empty,
LLR(k,i)=LLR_\text{clip}
; if
\mathcal{C}_{k,i,1}
is empty,
LLR(k,i)=-LLR_\text{clip}.
Parameters
num_bits_per_symbol (int) – Number of bits per constellation symbol
llr_clip_val (float) – The absolute values of LLRs are clipped to this value. Defaults to 20.0. Can also be a trainable variable.
Input
(y, r, dists, path_inds, path_syms) – Tuple:
y ([…,M], tf.complex or tf.float) – Channel outputs of the whitened channel
r ([…,num_streams, num_streams], same dtype as y) – Upper triangular channel matrix of the whitened channel
dists ([…,num_paths], tf.float) – Distance metric for each path (or candidate)
path_inds ([…,num_paths,num_streams], tf.int32) – Symbol indices for every stream of every path (or candidate)
path_syms ([…,num_path,num_streams], same dtype as y) – Constellation symbol for every stream of every path (or candidate)
Output
llr ([…num_streams,num_bits_per_symbol], tf.float) – LLRs for all bits of every stream
